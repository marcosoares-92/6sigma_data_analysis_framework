{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_1"
    ]
   },
   "outputs": [],
   "source": [
    "## Análise do Processo - Capacidade\n",
    "\n",
    "## CÉLULA 1: Instruções de carregamento do arquivo e bibliotecas a ser importadas\n",
    "\n",
    "\"\"\"\"\n",
    "    Para executar uma CÉLULA, pressione o botão \"Run\" no topo, com a CÉLULA selecionada, ou pressione:\n",
    "    \n",
    "    Shift + Enter\n",
    "\n",
    "-Se seus dados estiverem em um arquivo xlsx utilize a CÉLULA 2\n",
    "\n",
    "-Se seus dados estiverem em um arquivo csv contendo cabeçalhos, utilize a CÉLULA 3\n",
    "\n",
    "-Se seus dados estiverem em um arquivo csv sem cabeçalhos, utilize a CÉLULA 4\n",
    "\n",
    "-Utilize apenas a CÉLULA correta\n",
    "-Substitua o texto entre aspas na variável \"caminho\" pelo endereço do arquivo em sua máquina.\n",
    "\n",
    "EXECUTE ESTA CÉLULA ANTES DE PROSSEGUIR\n",
    "\n",
    "EXECUTE APENAS UMA CÉLULA POR VEZ\n",
    "\n",
    "-Caso deseje apagar a saída de uma célula carregada, mas não deseje carregar uma nova saída, vá à aba superior, escolha o ícone\n",
    "do teclado (open the command palette/ jupyter-notebook command group) e selecione clear cell output.\n",
    "\n",
    "@author: Marco César Prado Soares, MSc.\n",
    "Especialista Lean Six Sigma Master Black Belt, Eng. Químico, MSc. Eng. Mecatrônica (instrumentação) \n",
    "Marco.Soares@br.ey.com; marcosoares.feq@gmail.com\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_2"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 2: dados em arquivo xlsx\n",
    "\n",
    "caminho = \"D:\\Drive\\FM2S\\EAD\\Green Belt em Python\\Machine Learning - módulo 2 - ANN regression\\ANN.1 - Apartment price analysis\\prices_apartments.xlsx\"\n",
    "dataset = pd.read_excel(caminho)\n",
    "\n",
    "dataset\n",
    "#SIGA PARA A CÉLULA 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_3"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 3: dados em arquivo csv com cabeçalho\n",
    "\n",
    "caminho = \"D:\\Drive\\FM2S\\EAD\\Green Belt em Python\\Machine Learning - módulo 3 - ANN classification\\ANN.Class - 2 - advertising campaign\\delivery_app_data.csv\"\n",
    "dataset = pd.read_csv(caminho)\n",
    "\n",
    "dataset\n",
    "#SIGA PARA A CÉLULA 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_4"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 4: dados em arquivo csv sem cabeçalho\n",
    "\n",
    "caminho = \"D:\\Drive\\FM2S\\EAD\\Green Belt em Python\\Machine Learning - módulo 2 - ANN regression\\ANN.4 - Boston housing price\\housing_boston_data.txt\"\n",
    "dataset = pd.read_csv(caminho, delim_whitespace=True, header=None)\n",
    "\n",
    "#here, the dataset is in a textfile. In these cases, use delim_withespace = True\n",
    "#or df = pd.read_fwf('output_list.txt')\n",
    "#since data has no Head, keep header = None\n",
    "#if there is Head, eliminate ‘header’ from the arguments of the function\n",
    "\n",
    "dataset\n",
    "#SIGA PARA A CÉLULA 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_5"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 5: Eliminar linhas com entradas nulas\n",
    "\n",
    "\"\"\"\n",
    "-Utilize este CÉLULA apenas se desejar limpar as entradas nulas da sua base de dados\n",
    "\n",
    "-Esta CÉLULA eliminará todas as linhas contendo entradas nulas. Caso NÃO DESEJE ISTO, vá direto à CÉLULA 6, sem executar esta\n",
    "célula.\n",
    "\"\"\"\n",
    "\n",
    "dataset = dataset.dropna(axis=0)\n",
    "dataset\n",
    "#SIGA PARA A CÉLULA 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "CELL_6"
    ]
   },
   "source": [
    "# CÉLULA 6: Instruções Gerais\n",
    "\n",
    "### ATENÇÃO: NÃO EXECUTE ESTA CÉLULA - Ela contém apenas texto explicativo\n",
    "\n",
    "Este notebook destina-se à análise de capacidade de um processo, e a avaliação dos indicadores de capacidade.\n",
    "- Um processo capaz é aquele cuja variação natural (voz do processo - VOC) resulta em atendimento às especificações (voz do cliente - VOP).\n",
    "- Esta análise parte do pressuposto de que os dados seguem a distribuição normal.\n",
    "- Caso não sigam, você pode dividir os dados em subgrupos e avaliar as médias dos subgrupos.\n",
    "- De acordo com o Teorema Central do Limite, à medida que se divide em subgrupos, se toma as médias dos subgrupos, se divide essas médias em novos subgrupos, e assim sucessivamente, a distribuição estatística das médias tende à normal.\n",
    "- Esta é uma abordagem mais generalizante, elegante e poderosa que utilizar a transformação Box-Cox.\n",
    "\n",
    "## 1) Avaliação de capacidade e dos indicadores de capacidade\n",
    "\n",
    "- Aqui será construído o histograma dos dados, juntamente com a curva normal ajustada e os limites de especificação.\n",
    "- Também serão avaliados os indicadores de capacidade.\n",
    "- Note que só há sentido em realizar esta análise caso haja limites de especificação (requisitos de qualidade) definidos.\n",
    "- Veja nas instruções abaixo como lidar com situações nas quais apenas um limite de especificação está definido. Esta situação é bastante comum. Exemplos:\n",
    "\n",
    "- O processo não possui uma temperatura mínima, mas não pode exceder uma temperatura máxima (existe apenas o limite superior de especificação);\n",
    "- O capital de giro deve ser mantido em um valor mínimo, sob pena de insolvência da companhia, mas não existe um limite teórico máximo (existe apenas o limite inferior de especificação);\n",
    "- A criança deve ter altura mínima para usar o brinquedo (apenas limite inferior de especificação);\n",
    "- O elevador pode ser utilizado para transportar um determinado peso máximo ou número máximo de pessoas (existe apenas o limite superior de especificação).\n",
    "\n",
    "Siga para as CÉLULAS 7 a 9.\n",
    "-----------------------------------------\n",
    "\n",
    "- Mais uma vez, existe limitação na construção do histograma para a situação em que os dados são todos muito próximos. Neste caso, pode ser mais interessante utilizar os seguintes comandos do pacote qcc do R (no exemplo, as especificações são 0 e 18). Neste caso, o pacote qcc já está otimizado para situações como esta.\n",
    "\n",
    "        library(qcc)\n",
    "        \n",
    "        especificacao <- c(0,18)\n",
    "        \n",
    "        q <- qcc.groups(ytransform, sample= base$Mês)\n",
    "            #adicionar aqui os dados (ytransform) e o eixo x correspondente (meses)\n",
    "        \n",
    "        q <- qcc(q, type=\"xbar\", plot=TRUE, nsigmas=3, confidence.level = 0.95, breaks = \"scott\", \n",
    "                 add.stats = TRUE, print = TRUE, restore.par = TRUE) \n",
    "            #definir aqui o nivel de confianca (95%). O nsigmas representa a voz do processo: no caso, definiu-se 3 sigmas\n",
    "        \n",
    "        capability <- process.capability(q, spec.limits = limtransformado, nsigmas = 3)\n",
    "            #manter o mesmo nsigmas na ultima linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_7"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 7: Função para avaliação da capacidade e dos indicadores de capacidade do processo\n",
    "\n",
    "#Execute esta CÉLULA para carregar a função\n",
    "\n",
    "def capability(y, lim_spec, largura_da_barra, legenda_dos_dados = None, titulo_y = None, titulo_histograma = None):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import matplotlib\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    cc_const = {'Number of observations in sample n': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25],\n",
    "             'A2': [1.8800, 1.0230, 0.7290, 0.5770, 0.4830, 0.4190, 0.3730, 0.3370, 0.3080, 0.2850, 0.2660, 0.2490, 0.2350, 0.2230, 0.2120, 0.2030, 0.1940, 0.1870, 0.1800, 0.1730, 0.1670, 0.1620, 0.1570, 0.1530],\n",
    "             'A3': [2.6590, 1.9540, 1.6280, 1.4270, 1.2870, 1.1820, 1.0990, 1.0320, 0.9750, 0.9270, 0.8860, 0.8500, 0.8170, 0.7890, 0.7630, 0.7390, 0.7180, 0.6980, 0.6800, 0.6630, 0.6470, 0.6330, 0.6190, 0.6060],\n",
    "             'B3': [0.0000, 0.0000, 0.0000, 0.0000, 0.0300, 0.1180, 0.1850, 0.2390, 0.2840, 0.3210, 0.3540, 0.3820, 0.4060, 0.4280, 0.4480, 0.4660, 0.4820, 0.4970, 0.5100, 0.5230, 0.5340, 0.5450, 0.5550, 0.5650],\n",
    "             'B4': [3.2670, 2.5680, 2.2660, 2.0890, 1.9700, 1.8820, 1.8150, 1.7610, 1.7160, 1.6790, 1.6460, 1.6180, 1.5940, 1.5720, 1.5520, 1.5340, 1.5180, 1.5030, 1.4900, 1.4770, 1.4660, 1.4550, 1.4450, 1.4350],\n",
    "             '1/c4': [1.2533, 1.1284, 1.0854, 1.0638, 1.0510, 1.0423, 1.0363, 1.0317, 1.0281, 1.0252, 1.0229, 1.0210, 1.0194, 1.0180, 1.0168, 1.0157, 1.0148, 1.0140, 1.0133, 1.0126, 1.0119, 1.0114, 1.0109, 1.0105],\n",
    "             'D3': [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0760, 0.1360, 0.1840, 0.2230, 0.2560, 0.2830, 0.3070, 0.3280, 0.3470, 0.3630, 0.3780, 0.3910, 0.4030, 0.4150, 0.4250, 0.4340, 0.4430, 0.4510, 0.4590],\n",
    "             'D4': [3.2670, 2.5740, 2.2820, 2.1140, 2.0040, 1.9240, 1.8640, 1.8160, 1.7770, 1.7440, 1.7170, 1.6930, 1.6720, 1.6530, 1.6370, 1.6220, 1.6080, 1.5970, 1.5850, 1.5750, 1.5660, 1.5570, 1.5480, 1.5410],\n",
    "             '1/d2': [0.8865, 0.5907, 0.4857, 0.4299, 0.3946, 0.3698, 0.3512, 0.3367, 0.3249, 0.3152, 0.3069, 0.2998, 0.2935, 0.2880, 0.2831, 0.2787, 0.2747, 0.2711, 0.2677, 0.2647, 0.2618, 0.2592, 0.2567, 0.2544]\n",
    "             }\n",
    "    #Constantes dos graficos de controle e capacidade\n",
    "    \n",
    "    control_chart_const = pd.DataFrame(data = cc_const)\n",
    "    #dataframe com as constantes dos graficos de controle\n",
    "    \n",
    "    lsl = lim_spec[0]\n",
    "    #limite inferior de especificacao\n",
    "\n",
    "    usl = lim_spec[1]\n",
    "    #limite superior de especificacao\n",
    "    \n",
    "    target = np.average(lim_spec)\n",
    "    #centro do intervalo de especificacao\n",
    "    range_spec = usl - lsl\n",
    "    #range de especificacao\n",
    "    range_spec = abs(range_spec)\n",
    "    \n",
    "    #Calculo do bin size - largura do histograma:\n",
    "    #1: Encontrar o menor (lowest) e o maior (highest) valor dentro da tabela de dados)\n",
    "    #2: Calcular rangehist = highest - lowest\n",
    "    #3: Calcular quantidade de dados (samplesize) de entrada fornecidos\n",
    "    #4: Calcular a quantidade de celulas da tabela de frequencias (ncells)\n",
    "    #ncells = numero inteiro mais proximo da (raiz quadrada de samplesize)\n",
    "    #5: Calcular binsize = rangehist/(ncells)\n",
    "    #ATENCAO: Nao se esquecer de converter range, ncells, samplesize e binsize para valores absolutos (modulos)\n",
    "    #isso porque a largura do histograma tem que ser um numero positivo\n",
    "\n",
    "    y = y.reset_index(drop=True)\n",
    "    #faz com que os indices desta serie sejam consecutivos e a partir de zero\n",
    "\n",
    "    #Estatisticas gerais: media (mu) e desvio-padrao (sigma)\n",
    "    mu = y.mean() \n",
    "    sigma = y.std() \n",
    "\n",
    "    #Calculo do bin-size\n",
    "    highest = y.max()\n",
    "    lowest = y.min()\n",
    "    rangehist = highest - lowest\n",
    "    rangehist = abs(rangehist)\n",
    "    #garante que sera um numero positivo\n",
    "    samplesize = y.count() #contagem do total de entradas\n",
    "    ncells = (samplesize)**0.5 #potenciacao: ** - raiz quadrada de samplesize\n",
    "    #resultado da raiz quadrada e sempre positivo\n",
    "    ncells = round(ncells) #numero \"redondo\" mais proximo\n",
    "    ncells = int(ncells) #parte inteira do numero arredondado\n",
    "    #ncells = numero de linhas da tabela de frequencias\n",
    "    binsize = rangehist/ncells\n",
    "    binsize = round(binsize)\n",
    "    binsize = int(binsize) #precisa ser inteiro\n",
    "    \n",
    "    #Construcao da tabela de frequencias\n",
    "\n",
    "    j = 0 #indice da tabela de frequencias\n",
    "    #Este indice e diferente do ordenamento dos valores em ordem crescente\n",
    "    xhist = []\n",
    "    #Lista vazia que contera os x do histograma\n",
    "    yhist = []\n",
    "    #Listas vazia que conteras o y do histograma\n",
    "    hist_labels = []\n",
    "    #Esta lista gravara os limites da barra na forma de strings\n",
    "\n",
    "    pontomediodabarra = lowest + binsize/2 \n",
    "    limitedabarra = lowest + binsize\n",
    "    #ponto medio da barra \n",
    "    #limite da primeira barra do histograma\n",
    "    seriedohist1 = y\n",
    "    seriedohist1 = seriedohist1.sort_values(ascending=True)\n",
    "    #serie com os valores em ordem crescente\n",
    "    seriedohist1 = seriedohist1.reset_index(drop=True)\n",
    "    #garante que a nova serie tenha indices consecutivos, iniciando em zero\n",
    "    i = 0 #linha inicial da serie do histograma em ordem crescente\n",
    "    valcomparado = seriedohist1[i]\n",
    "    #primeiro valor da serie, o mais baixo\n",
    "\n",
    "    while (j <= (ncells-1)):\n",
    "        \n",
    "        #para quando termina o numero de linhas da tabela\n",
    "        xhist.append(pontomediodabarra)\n",
    "        #tempo da tabela de frequencias\n",
    "        cont = 0\n",
    "        #variavel de contagem do histograma\n",
    "        #contagem deve ser reiniciada\n",
    "       \n",
    "        if (i < samplesize):\n",
    "            #2 condicionais para impedir que um termo de indice inexistente\n",
    "            #seja acessado\n",
    "            while (valcomparado <= limitedabarra) and (valcomparado < highest):\n",
    "                #o segundo criterio garante a parada em casos em que os dados sao\n",
    "                #muito proximos\n",
    "                    cont = cont + 1 #adiciona contagem a tabela de frequencias\n",
    "                    i = i + 1\n",
    "                    \n",
    "                    if (i < samplesize): \n",
    "                        valcomparado = seriedohist1[i]\n",
    "        \n",
    "        yhist.append(cont) #valor de ocorrencias contadas\n",
    "        \n",
    "        limite_infdabarra = pontomediodabarra - binsize/2\n",
    "        rotulo = \"%.2f - %.2f\" %(limite_infdabarra, limitedabarra)\n",
    "        #intervalo da tabela de frequencias\n",
    "        hist_labels.append(rotulo)\n",
    "        \n",
    "        pontomediodabarra = pontomediodabarra + binsize\n",
    "        #tanto os pontos medios quanto os limites se deslocam do mesmo intervalo\n",
    "        \n",
    "        limitedabarra = limitedabarra + binsize\n",
    "        #proxima barra\n",
    "        \n",
    "        j = j + 1\n",
    "    \n",
    "    #Temos que verificar se o valor maximo foi incluido\n",
    "    #isso porque o processo de aproximacao por numero inteiro pode ter\n",
    "    #arredondado para baixo e excluido o limite superior\n",
    "    #Porem, note que na ultima iteracao o limite superior da barra foi \n",
    "    #somado de binsize, mas como j ja e maior que ncells-1, o loop parou\n",
    "    \n",
    "    #assim, o limitedabarra nesse momento e o limite da barra que seria\n",
    "    #construida em seguida, nao da ultima barra da tabela de frequencias\n",
    "    #isso pode fazer com que esta barra ja seja maior que o highest\n",
    "    \n",
    "    #note porem que nao aumentamos o valor do limite inferior da barra\n",
    "    #por isso, basta vermos se ele mais o binsize sao menores que o valor mais alto\n",
    "    \n",
    "    \n",
    "    while ((limite_infdabarra+binsize) < highest):\n",
    "        \n",
    "        #vamos criar novas linhas ate que o ponto mais alto do histograma\n",
    "        #tenha sido contado\n",
    "        ncells = ncells + 1 #adiciona uma linha a tabela de frequencias\n",
    "        xhist.append(pontomediodabarra)\n",
    "        \n",
    "        cont = 0 #variavel de contagem do histograma\n",
    "        \n",
    "        while (valcomparado <= limitedabarra):\n",
    "                cont = cont + 1 #adiciona contagem a tabela de frequencias\n",
    "                i = i + 1\n",
    "                if (i < samplesize):\n",
    "                    valcomparado = seriedohist1[i]\n",
    "                    #apenas se i ainda nao e maior que o total de dados\n",
    "                \n",
    "                else: \n",
    "                    \n",
    "                    break\n",
    "        \n",
    "        #parar o loop se i atingiu um tamanho maior que a quantidade \n",
    "        #de dados.Temos que ter este cuidado porque estamos acrescentando\n",
    "        #mais linhas a tabela de frequencias para corrigir a aproximacao\n",
    "        #de ncells por um numero inteiro\n",
    "        \n",
    "        yhist.append(cont) #valor de ocorrencias contadas\n",
    "        \n",
    "        limite_infdabarra = pontomediodabarra - binsize/2\n",
    "        rotulo = \"%.2f - %.2f\" %(limite_infdabarra, limitedabarra)\n",
    "        #%.2f apenas 2 casas decimais\n",
    "        #intervalo da tabela de frequencias\n",
    "        hist_labels.append(rotulo)\n",
    "        \n",
    "        pontomediodabarra = pontomediodabarra + binsize\n",
    "        #tanto os pontos medios quanto os limites se deslocam do mesmo intervalo\n",
    "        \n",
    "        limitedabarra = limitedabarra + binsize\n",
    "        #proxima barra\n",
    "        \n",
    "    estatisticas_col1 = []\n",
    "    #contera as descricoes das colunas da tabela de estatisticas gerais\n",
    "    estatisticas_col2 = []\n",
    "    #contera os valores da tabela de estatisticas gerais\n",
    "    \n",
    "    estatisticas_col1.append(\"Total de dados avaliados\")\n",
    "    estatisticas_col2.append(samplesize)\n",
    "    estatisticas_col1.append(\"Média (mu)\")\n",
    "    estatisticas_col2.append(mu)\n",
    "    estatisticas_col1.append(\"Desvio-padrão (sigma)\")\n",
    "    estatisticas_col2.append(sigma)\n",
    "    estatisticas_col1.append(\"Valor mais elevado\")\n",
    "    estatisticas_col2.append(highest)\n",
    "    estatisticas_col1.append(\"Valor mais baixo\")\n",
    "    estatisticas_col2.append(lowest)\n",
    "    estatisticas_col1.append(\"Range dos dados\\n(valor máximo - valor mínimo)\")\n",
    "    estatisticas_col2.append(rangehist)\n",
    "    estatisticas_col1.append(\"Range de especificação\\n(limite superior - limite inferior)\")\n",
    "    estatisticas_col2.append(range_spec)\n",
    "    estatisticas_col1.append(\"Bin size\\n(largura da barra do histograma)\")\n",
    "    estatisticas_col2.append(binsize)\n",
    "    estatisticas_col1.append(\"Quantidade de linhas\\nna tabela de frequências\")\n",
    "    estatisticas_col2.append(ncells)\n",
    "    #como o comando append grava linha a linha em sequencia, garantimos\n",
    "    #a correspondencia das colunas\n",
    "    #Assim como em qualquer string, incluindo de rotulos de graficos\n",
    "    #os \\n sao lidos como quebra de linha\n",
    "    \n",
    "    #avaliacao dos indicadores\n",
    "    #constante 1/c4\n",
    "    if (samplesize < 25):\n",
    "        \n",
    "        constant = control_chart_const.loc[(samplesize-2), ['1/c4']]\n",
    "        #2 elementos correspondem ao indice zero, 3 elementos ao indice 1, etc\n",
    "        #24 elementos correspondem ao indice 22\n",
    "        #necessario sempre subtrair 2\n",
    "    \n",
    "    else:\n",
    "        constant = control_chart_const.loc[23, ['1/c4']]\n",
    "        #ultima linha do dataframe\n",
    "    \n",
    "    #le como lista, e cria uma lista de um unico elemento 'constant'\n",
    "    #ocorre quando o .loc le elementos do pandas: daframes criados a partir \n",
    "    #de dicionarios, dataframes criados pelo agrupamento de outros dados, etc\n",
    "    \n",
    "    sigma_corrected = sigma*(constant[0])\n",
    "    \n",
    "    estatisticas_col1.append(\"Indicadores de capacidade:\")\n",
    "    estatisticas_col2.append(None)\n",
    "    #garantir que nao haja problema de compatibilidade de tipo de variavel\n",
    "    #ao mesmo tempo em que deixa a celula vazia\n",
    "    \n",
    "    cp = (range_spec)/(6*sigma_corrected)\n",
    "    cr = 100*(6*sigma_corrected)/(range_spec)\n",
    "    cm = (range_spec)/(8*sigma_corrected)\n",
    "    zu = (usl-mu)/(sigma_corrected)\n",
    "    zl = (mu-lsl)/(sigma_corrected)\n",
    "    z_min = np.minimum(zu, zl)\n",
    "    #seleciona o valor minimo entre os dois\n",
    "    cpk = (z_min)/3\n",
    "    \n",
    "    fator = 1 + ((mu-target)**2)/((sigma_corrected)**2)\n",
    "    fator = np.sqrt(fator) #raiz quadrada\n",
    "    cpm = (cp)/(fator)\n",
    "    \n",
    "    estatisticas_col1.append(\"Cp\")\n",
    "    estatisticas_col2.append(cp)\n",
    "    estatisticas_col1.append(\"Cr\")\n",
    "    estatisticas_col2.append(cr)\n",
    "    estatisticas_col1.append(\"Cm\")\n",
    "    estatisticas_col2.append(cm)\n",
    "    estatisticas_col1.append(\"Zu\")\n",
    "    estatisticas_col2.append(zu)\n",
    "    estatisticas_col1.append(\"Zl\")\n",
    "    estatisticas_col2.append(zl)\n",
    "    estatisticas_col1.append(\"Zmin\")\n",
    "    estatisticas_col2.append(z_min)\n",
    "    estatisticas_col1.append(\"Cpk\")\n",
    "    estatisticas_col2.append(cpk)\n",
    "    estatisticas_col1.append(\"Cpm\")\n",
    "    estatisticas_col2.append(cpm)\n",
    "    \n",
    "    d1 = {\"Estatísticas gerais dos dados e Indicadores\": estatisticas_col1, \"Valor calculado\": estatisticas_col2}\n",
    "    #dicionario das duas series, para criar o dataframe com as descricoes\n",
    "    estatisticas_gerais = pd.DataFrame(data = d1)\n",
    "    \n",
    "    #Casos os títulos estejam presentes (valor nao e None):\n",
    "    #vamos utiliza-los\n",
    "    #Caso contrario, vamos criar nomenclaturas genericas para o histograma\n",
    "    \n",
    "    eixo_y = \"Counting/Frequency\"\n",
    "    \n",
    "    if not (legenda_dos_dados is None):\n",
    "        xlabel = legenda_dos_dados\n",
    "    \n",
    "    else:\n",
    "        xlabel = \"Frequency\\n table data\"\n",
    "    \n",
    "    if not (titulo_y is None):\n",
    "        eixo_x = titulo_y\n",
    "        #lembre-se que no histograma, os dados originais vao pro eixo X\n",
    "        #O eixo Y vira o eixo da contagem/frequencia daqueles dados\n",
    "    \n",
    "    else:\n",
    "        eixo_x = \"X: Mean value of the interval\"\n",
    "    \n",
    "    if not (titulo_histograma is None):\n",
    "        string1 = \"- Target = %.2f, $\\mu = %.2f$, $\\sigma = %.2f$\" %(target, mu, sigma)\n",
    "        main_label = titulo_histograma + string1\n",
    "        #concatena a string do titulo a string com a media e desvio-padrao\n",
    "        #%.2f: o numero entre %. e f indica a quantidade de casas decimais da \n",
    "        #variavel float f. No caso, arredondamos para 2 casas\n",
    "        #NAO SE ESQUECA DO PONTO: ele que indicara que sera arredondado o \n",
    "        #numero de casas\n",
    "    \n",
    "    else:\n",
    "        main_label = \"Data Histogram - Target = %.2f, $\\mu = %.2f$, $\\sigma = %.2f$\" %(target, mu, sigma)\n",
    "        #os simbolos $\\ $ substituem o simbolo pela letra grega\n",
    "    \n",
    "    d2 = {\"Intervalos considerados\": hist_labels, eixo_x: xhist, eixo_y: yhist}\n",
    "    #dicionario que compoe a tabela de frequencias\n",
    "    tab_frequencias = pd.DataFrame(data = d2)\n",
    "    #cria a tabela de frequencias como um dataframe de saida\n",
    "    \n",
    "    \"\"\"\n",
    "    Normal curve equation\n",
    "    \n",
    "    y = p(X) = (1/((sigma)*sqrt(2*pi)))*exp((-1)*(X-mu)²/2(sigma²))\n",
    "    0 <= p(X) <= 1\n",
    "    mu = mean value of X\n",
    "    sigma = standard deviation of X\n",
    "    sqrt = square root function\n",
    "    pi = 3.14159...\n",
    "    e = 2.71828...\n",
    "    exp = e** = e^ = exponential function\n",
    "    \n",
    "    numpy functions available:\n",
    "        np.sqrt(X): square root of X\n",
    "        np.pi = value of pi\n",
    "        np.exp(X) = exponential function of X = e**X = e^X = exp(X)\n",
    "    \n",
    "    \"\"\"\n",
    "    #parametros da normal ja calculados:\n",
    "    #mu e sigma\n",
    "    #numero de bins: ncells\n",
    "    #limites de especificacao: lsl,usl - target\n",
    "    \n",
    "    #valor maximo do histograma\n",
    "    max_hist = max(yhist)\n",
    "    #seleciona o valor maximo da serie, para ajustar a curva normal\n",
    "    #isso porque a normal é criada com valores entre 0 e 1\n",
    "    #multiplicando ela por max_hist, fazemos ela se adequar a altura do histograma\n",
    "    \n",
    "    #construir a normal ajustada/esperada\n",
    "    #vamos criar pontos ao redor da media mu - 4sigma ate mu + 4sigma, \n",
    "    #de modo a garantir a quase totalidade da curva normal. \n",
    "    #O incremento será de 0.10 sigma a cada iteracao\n",
    "    x_inf = mu -(4)*sigma\n",
    "    x_sup = mu + 4*sigma\n",
    "    x_inc = (0.10)*sigma\n",
    "    \n",
    "    x_normal_adj = []\n",
    "    y_normal_adj = []\n",
    "    \n",
    "    x_adj = x_inf\n",
    "    y_adj = ((1 / (np.sqrt(2 * np.pi) * sigma)) *np.exp(-0.5 * (1 / sigma * (x_adj - mu))**2))\n",
    "    x_normal_adj.append(x_adj)\n",
    "    y_normal_adj.append(y_adj)\n",
    "    \n",
    "    while(x_adj < x_sup): \n",
    "        \n",
    "        x_adj = x_adj + x_inc\n",
    "        y_adj = ((1 / (np.sqrt(2 * np.pi) * sigma)) *np.exp(-0.5 * (1 / sigma * (x_adj - mu))**2))\n",
    "        x_normal_adj.append(x_adj)\n",
    "        y_normal_adj.append(y_adj)\n",
    "    \n",
    "    #vamos ajustar a altura da curva ao histograma. Para isso, precisamos\n",
    "    #calcular quantas vezes o ponto mais alto do histograma é maior que o ponto\n",
    "    #mais alto da normal (chamaremos essa relação de fator). A seguir,\n",
    "    #multiplicamos cada elemento da normal por este mesmo fator\n",
    "    max_normal = max(y_normal_adj) \n",
    "    #maximo da normal ajustada, numero entre 0 e 1\n",
    "    \n",
    "    fator = (max_hist)/(max_normal)\n",
    "    size_normal = len(y_normal_adj) #quantidade de dados criados\n",
    "    \n",
    "    i = 0\n",
    "    while (i < size_normal):\n",
    "        y_normal_adj[i] = (y_normal_adj[i])*(fator)\n",
    "        i = i + 1\n",
    "    \n",
    "    #Fazer o grafico\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.bar(xhist, yhist, width = largura_da_barra, label=xlabel, color='blue')\n",
    "    #ajuste manualmente a largura, width, para deixar as barras mais ou menos proximas\n",
    "    #adicionar a normal\n",
    "    ax.plot(x_normal_adj, y_normal_adj, color = 'black', label = 'Adjusted/expected\\n normal curve')\n",
    "    ax.set_xlabel(eixo_x)\n",
    "    ax.set_ylabel(eixo_y)\n",
    "    ax.set_title(main_label)\n",
    "    ax.set_xticks(xhist)\n",
    "    \n",
    "    #adicionar limites de especificacao como retas verticais tracejadas:\n",
    "    #comando ax.vline() - vertical line. linhas horizontais: ax.hline() - horizontal line\n",
    "    #adicionar curva em degraus: ax.step()\n",
    "    #limite superior de especificacao:\n",
    "    ax.axvline(usl, color = 'red', linestyle = 'dashed', label = 'Specification limits\\n and target')\n",
    "    #limite inferior de especificacao:\n",
    "    ax.axvline(lsl, color = 'red', linestyle = 'dashed')\n",
    "    #target central\n",
    "    ax.axvline(target, color = 'red', linestyle = 'dashed')\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.grid(True) #mude para False, caso não deseje ver as linhas de grade\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return estatisticas_gerais, tab_frequencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "CELL_8"
    ]
   },
   "source": [
    "# CÉLULA 8: Função para avaliação de capacidade do processo\n",
    "\n",
    "### ATENÇÃO: NÃO EXECUTE ESTA CÉLULA - Ela contém apenas texto explicativo\n",
    "\n",
    "##### INTERPRETAÇÃO BÁSICA DO Cpk (indicador de capacidade)\n",
    "\n",
    "- O Cpk avalia simultaneamente a centralidade do processo, i.e., se os resultados estão bem e simetricamente distribuídos ao longo da média do intervalo de especificação; e se o processo atende aos requisitos de qualidade.\n",
    "\n",
    "###### Em geral, toma-se como mínimo aceitável Cpk = 1, e define-se como objetivo de qualidade alcançar Cpk = 1.33 (valor desejável).\n",
    "\n",
    "###### Um processo 6-sigma apresenta Cpk = +2\n",
    "\n",
    "- Baixos Cpks (e principalmente Cpks negativos) indicam processos mal centrados e com muitos resultados distantes das especificações. \n",
    "\n",
    "- Quanto mais negativo o indicador, mais distantes os resultados estão das especificações.\n",
    "\n",
    "INSTRUÇÕES:\n",
    "\n",
    "1) Esta função retorna 2 dataframes:\n",
    "    \n",
    "        1) dataframe estatisticas_gerais, um resumo das estatísticas gerais dos dados: total de dados avaliados; média; desvio-\n",
    "        padrão; valor mais elevado; valor mais baixo; range dos dados; range das especificações; e bin size, a largura da barra \n",
    "        do histograma. \n",
    "\n",
    "        Este dataframe também mostra os indicadores de capacidade\n",
    "    \n",
    "    \n",
    "        2) dataframe tab_frequencias, que mostra a tabela de frequencias usada para a construção do histograma\n",
    "    \n",
    "\n",
    "2) Os parâmetros x e y da função devem ser APENAS LISTAS, não dataframe(s)\n",
    "\n",
    "3) FORNEÇA OS LIMITES DE ESPECIFICAÇÃO COMO UMA LISTA DE 2 VALORES:\n",
    "    \n",
    "        lim_spec = [lim_inf, lim_sup]\n",
    "    \n",
    "        Exemplo: se os limites são entre 10 a 20 kg:\n",
    "            lim_spec = [10, 20]\n",
    "    \n",
    "        se os limites são pH entre 2.71 e 3.05:\n",
    "            lim_spec = [2.71, 3.05]\n",
    "    \n",
    "- Não se esqueça que o separador decimal é o ponto. \n",
    "\n",
    "- O primeiro valor será lido como limite inferior, o segundo como limite superior.\n",
    "\n",
    "3) Esta função retorna 2 dataframes. Deste modo, você precisa chamar 2\n",
    "   daframes, não apenas um.\n",
    "\n",
    "Exemplo: caso deseje salvar o dataframe estatisticas_gerais em df1, e o dataframe tab_frequencias em df2, e os dados estão na variável y:\n",
    "    \n",
    "       df1, df2 = histograma(x, y, legenda_dos_dados = None, titulo_y = None, titulo_histograma = None, largura_da_barra = 15)\n",
    "    \n",
    "Note que o primeiro dataframe será sempre o correspondente à saída estatisticas_gerais, enquanto que o segundo será a tab_frequencias.\n",
    "   \n",
    "Você pode dar outros nomes para os dataframes chamados:\n",
    "   \n",
    "       estatisticas_gerais, tab_frequencias = histograma(x, y, legenda_dos_dados = None, titulo_y = None, titulo_histograma = None, largura_da_barra = 15)\n",
    "\n",
    "4) Altere manualmente o valor de largura_da_barra ate conseguir visualizar o histograma de forma clara.\n",
    "\n",
    "5) Os demais parâmetros são textos (strings). Declare-os entre aspas ou mantenha o valor None.\n",
    "\n",
    "\n",
    "### Caso esteja lidando com uma SITUAÇÃO NA QUAL NÃO EXISTE UMA DAS ESPECIFICAÇÕES: \n",
    "\n",
    "1) No código da função, apague da linha 'target' até 'abs(range_spec)', ou seja, todo o trecho a seguir:\n",
    "\n",
    "        target = np.average(lim_spec)\n",
    "        #centro do intervalo de especificacao\n",
    "        range_spec = usl - lsl\n",
    "        #range de especificacao\n",
    "        range_spec = abs(range_spec)\n",
    "\n",
    "2) Localize as seguintes linhas do código da função. O limite inferior de especificação é indicado pela variável lsl (\"lower specification limit\"), enquanto que o limite superior de especificação é indicado pela variável usl (\"upper specification limit\").\n",
    "\n",
    "        lsl = lim_spec[0]\n",
    "        #limite inferior de especificacao\n",
    "\n",
    "        usl = lim_spec[1]\n",
    "        #limite superior de especificacao\n",
    "\n",
    "        target = np.average(lim_spec)\n",
    "        #centro do intervalo de especificacao\n",
    "        range_spec = usl - lsl\n",
    "        #range de especificacao\n",
    "        range_spec = abs(range_spec)\n",
    " \n",
    "3) Apague o limite de especificação que não é usado, e defina manualmente como ler o limite correto. \n",
    "Exemplo: se houver um limite inferior de especificação igual a -10.5, substitua todo o código acima por:\n",
    "        \n",
    "        lsl = lim_spec\n",
    "\n",
    "Nos argumentos da função, você então declarará lim_spec como o valor do limite de especificação. Note que, por ser um valor único, não é necessário utilizar colchetes:\n",
    "        \n",
    "        estatisticas_gerais, tab_frequencias = capability(y, lim_spec = -10.5, largura_da_barra, legenda_dos_dados = None, titulo_y = None, titulo_histograma = None)\n",
    "\n",
    "Se, por outro lado, existe apenas o limite superior de especificação (por exemplo, 2.4), o código anterior deve ser substituído por:\n",
    "\n",
    "        usl = lim_spec\n",
    "\n",
    "E, nos argumentos da função, você teria:\n",
    "        \n",
    "        estatisticas_gerais, tab_frequencias = capability(y, lim_spec = 2.4, largura_da_barra, legenda_dos_dados = None, titulo_y = None, titulo_histograma = None)\n",
    "\n",
    "4) Após fazer esta modificação, vá ao trecho do código que se refere à criação de tabelas/cálculo de indicadores e apague tudo que se refere a range_spec, target e ao indicador relacionado ao limite de especificação que não está presente. \n",
    "\n",
    "- Também apague zmin, cpk e cpm.\n",
    "\n",
    "###### Isto porque ESTES INDICADORES NÃO SÃO INTERPRETÁVEIS CASO NÃO EXISTA UM dos limites de especificação.\n",
    "\n",
    "- Isto significa que você deverá apagar as seguintes linhas:\n",
    "\n",
    "        cp = (range_spec)/(6*sigma_corrected)\n",
    "        cr = 100*(6*sigma_corrected)/(range_spec)\n",
    "        cm = (range_spec)/(8*sigma_corrected)\n",
    "\n",
    "        z_min = np.minimum(zu, zl)\n",
    "        #seleciona o valor minimo entre os dois\n",
    "        cpk = (z_min)/3\n",
    "\n",
    "        fator = 1 + ((mu-target)**2)/((sigma_corrected)**2)\n",
    "        fator = np.sqrt(fator) #raiz quadrada\n",
    "        cpm = (cp)/(fator)\n",
    "\n",
    "        estatisticas_col1.append(\"Cp\")\n",
    "        estatisticas_col2.append(cp)\n",
    "        estatisticas_col1.append(\"Cr\")\n",
    "        estatisticas_col2.append(cr)\n",
    "        estatisticas_col1.append(\"Cm\")\n",
    "        estatisticas_col2.append(cm)\n",
    "\n",
    "        estatisticas_col1.append(\"Zmin\")\n",
    "        estatisticas_col2.append(z_min)\n",
    "        estatisticas_col1.append(\"Cpk\")\n",
    "        estatisticas_col2.append(cpk)\n",
    "        estatisticas_col1.append(\"Cpm\")\n",
    "        estatisticas_col2.append(cpm)\n",
    "    \n",
    "    - Se houver apenas limite de especificação superior, deve ser apagado o Z referente ao limite inferior (lower), Zl, presente \n",
    "        nas linhas:\n",
    "    \n",
    "            zl = (mu-lsl)/(sigma_corrected)\n",
    "            estatisticas_col1.append(\"Zl\")\n",
    "            estatisticas_col2.append(zl)\n",
    "    \n",
    "     - Se houver apenas limite de especificação inferior, deve ser apagado o Z referente ao limite superior (upper), Zu, \n",
    "         presente nas linhas:\n",
    "    \n",
    "            zu = (usl-mu)/(sigma_corrected)\n",
    "            estatisticas_col1.append(\"Zu\")\n",
    "            estatisticas_col2.append(zu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_9"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 9: ANÁLISE DE CAPACIDADE DO SEU PROCESSO\n",
    "\n",
    "#DEFINA A VARIAVEL y para a qual será construído o histograma e será feita a análise de capacidade. \n",
    "#Basta substituir o valor entre aspas pelo nome da coluna onde está Y:\n",
    "\n",
    "y = dataset['Y']\n",
    "\n",
    "#NOTA: o valor y necessariamente deve ser uma série.\n",
    "\n",
    "#DEFINA O limite inferior de especificação. Basta substituir o valor zero pelo valor numérico do seu limite. Lembre-se que o\n",
    "#separador decimal é o ponto. Se seu limite for 2.4, faça lim_inf = 2.4\n",
    "lim_inf = 0\n",
    "\n",
    "#DEFINA O limite superior de especificação. Basta substituir o valor zero pelo valor numérico do seu limite. Lembre-se que o\n",
    "#separador decimal é o ponto. Se seu limite for 7.5, faça lim_inf = 7.5\n",
    "lim_sup = 0\n",
    "\n",
    "\"\"\"\n",
    "VEJA NAS INSTRUÇÕES ACIMA COMO PROCEDER CASO EXISTA UM ÚNICO VALOR DE LIMITE DE ESPECIFICAÇÃO (apenas o limite inferior ou\n",
    "apenas o limite superior)\n",
    "\"\"\"\n",
    "\n",
    "estatisticas_gerais, tab_frequencias = capability(y = y, lim_spec = [lim_inf, lim_sup], largura_da_barra = 10, legenda_dos_dados = None, titulo_y = None, titulo_histograma = None)\n",
    "\n",
    "# Altere manualmente o valor numérico da largura_da_barra do histograma até alcançar um espaçamento mínimo entre barras\n",
    "#consecutivas. O valor da largura da barra depende de cada conjunto particular de dados utilizado.\n",
    "\n",
    "\"\"\"\n",
    "VEJA NAS INSTRUÇÕES ACIMA COMO PROCEDER CASO EXISTA UM ÚNICO VALOR DE LIMITE DE ESPECIFICAÇÃO (apenas o limite inferior ou\n",
    "apenas o limite superior). Você terá de substituir os colchetes na função acima pelo valor numérico deste limite. Por exemplo,\n",
    "se houver apenas uma especificação igual a -6.52, lim_spec = [lim_inf, lim_sup] deve ser substituído por lim_spec = -6.52\n",
    "\n",
    "Substitua os demais campos None de acordo com as instruções dadas na CÉLULA 8.\n",
    "- Os títulos e legendas devem ser fornecidos como um texto entre aspas.\n",
    "\"\"\"\n",
    "\n",
    "estatisticas_gerais\n",
    "tab_frequencias\n",
    "\n",
    "\"\"\"VOCÊ DESEJA EXPORTAR OS DADOS?\n",
    "Caso deseje exportar os dados, copie as seguintes linhas para o espaço não-vermelho após as aspas. Substitua o endereço pela\n",
    "pasta onde você deseja salvar seu arquivo. Substitua estatisticas e tabela_freq pelos nomes que deseja para seus arquivos. \n",
    "Mantenha a extensão csv. Você pode também optar por exportar apenas uma das tabelas (neste caso, copie apenas a desejada).\n",
    "\n",
    "estatisticas_gerais.to_csv(r\"D:\\Drive\\FM2S\\EAD\\Green Belt em Python\\Machine Learning - módulo 3 - ANN classification\\ANN.Class - 1 - user satisfaction\\estatisticas.csv\", index = False)\n",
    "\n",
    "tab_frequencias.to_csv(r\"D:\\Drive\\FM2S\\EAD\\Green Belt em Python\\Machine Learning - módulo 3 - ANN classification\\ANN.Class - 1 - user satisfaction\\tabela_freq.csv\", index = False)\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
