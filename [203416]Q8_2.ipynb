{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "[203416]Q8.2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFi1P1DT4FgS"
      },
      "source": [
        "# Solving a Maze with Deep Reinforcement Learning\n",
        "# FEEC/Unicamp - July/2020\n",
        "# Based on https://www.samyzaf.com/ML/rl/qmaze.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjhi5kdG4FgT"
      },
      "source": [
        "### Importações e definições"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aDpGQDz4Fg0"
      },
      "source": [
        "from __future__ import print_function\n",
        "from time import sleep\n",
        "from IPython import display\n",
        "import pylab as pl\n",
        "import os, sys, time, datetime, json, random\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import SGD , Adam, RMSprop\n",
        "from keras.layers.advanced_activations import PReLU\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQs4V1wY_jJS"
      },
      "source": [
        "visited_mark = 0.8  # Cells visited by the rat will be painted by gray 0.8\n",
        "rat_mark = 0.5      # The current rat cell will be painted by gray 0.5\n",
        "LEFT = 0\n",
        "UP = 1\n",
        "RIGHT = 2\n",
        "DOWN = 3\n",
        "\n",
        "# Actions dictionary\n",
        "actions_dict = {\n",
        "    LEFT: 'left',\n",
        "    UP: 'up',\n",
        "    RIGHT: 'right',\n",
        "    DOWN: 'down',\n",
        "}\n",
        "\n",
        "num_actions = len(actions_dict)\n",
        "\n",
        "# Exploration factor\n",
        "epsilon = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1gPgFfQAMu_"
      },
      "source": [
        "# maze is a 2d Numpy array of floats between 0.0 to 1.0\n",
        "# 1.0 corresponds to a free cell, and 0.0 an occupied cell\n",
        "# rat = (row, col) initial rat position (defaults to (0,0))\n",
        "\n",
        "class Qmaze(object):\n",
        "    def __init__(self, maze, rat=(0,0)):\n",
        "        self._maze = np.array(maze)\n",
        "        nrows, ncols = self._maze.shape\n",
        "        self.target = (nrows-1, ncols-1)   # target cell where the \"cheese\" is\n",
        "        self.free_cells = [(r,c) for r in range(nrows) for c in range(ncols) if self._maze[r,c] == 1.0]\n",
        "        self.free_cells.remove(self.target)\n",
        "        if self._maze[self.target] == 0.0:\n",
        "            raise Exception(\"Invalid maze: target cell cannot be blocked!\")\n",
        "        if not rat in self.free_cells:\n",
        "            raise Exception(\"Invalid Rat Location: must sit on a free cell\")\n",
        "        self.reset(rat)\n",
        "\n",
        "    def reset(self, rat):\n",
        "        self.rat = rat\n",
        "        self.maze = np.copy(self._maze)\n",
        "        nrows, ncols = self.maze.shape\n",
        "        row, col = rat\n",
        "        self.maze[row, col] = rat_mark\n",
        "        self.state = (row, col, 'start')\n",
        "        self.min_reward = -0.5 * self.maze.size\n",
        "        self.total_reward = 0\n",
        "        self.visited = set()\n",
        "\n",
        "    def update_state(self, action):\n",
        "        nrows, ncols = self.maze.shape\n",
        "        nrow, ncol, nmode = rat_row, rat_col, mode = self.state\n",
        "\n",
        "        if self.maze[rat_row, rat_col] > 0.0:\n",
        "            self.visited.add((rat_row, rat_col))  # mark visited cell\n",
        "\n",
        "        valid_actions = self.valid_actions()\n",
        "                \n",
        "        if not valid_actions:\n",
        "            nmode = 'blocked'\n",
        "        elif action in valid_actions:\n",
        "            nmode = 'valid'\n",
        "            if action == LEFT:\n",
        "                ncol -= 1\n",
        "            elif action == UP:\n",
        "                nrow -= 1\n",
        "            if action == RIGHT:\n",
        "                ncol += 1\n",
        "            elif action == DOWN:\n",
        "                nrow += 1\n",
        "        else:                  # invalid action, no change in rat position\n",
        "            mode = 'invalid'\n",
        "\n",
        "        # new state\n",
        "        self.state = (nrow, ncol, nmode)\n",
        "\n",
        "    def get_reward(self):\n",
        "        rat_row, rat_col, mode = self.state\n",
        "        nrows, ncols = self.maze.shape\n",
        "        if rat_row == nrows-1 and rat_col == ncols-1:\n",
        "            return 1.0\n",
        "        if mode == 'blocked':\n",
        "            return self.min_reward - 1\n",
        "        if (rat_row, rat_col) in self.visited:\n",
        "            return -0.25\n",
        "        if mode == 'invalid':\n",
        "            return -0.75\n",
        "        if mode == 'valid':\n",
        "            return -0.04\n",
        "\n",
        "    def act(self, action):\n",
        "        self.update_state(action)\n",
        "        reward = self.get_reward()\n",
        "        self.total_reward += reward\n",
        "        status = self.game_status()\n",
        "        envstate = self.observe()\n",
        "        return envstate, reward, status\n",
        "\n",
        "    def observe(self):\n",
        "        canvas = self.draw_env()\n",
        "        envstate = canvas.reshape((1, -1))\n",
        "        return envstate\n",
        "\n",
        "    def draw_env(self):\n",
        "        canvas = np.copy(self.maze)\n",
        "        nrows, ncols = self.maze.shape\n",
        "        # clear all visual marks\n",
        "        for r in range(nrows):\n",
        "            for c in range(ncols):\n",
        "                if canvas[r,c] > 0.0:\n",
        "                    canvas[r,c] = 1.0\n",
        "        # draw the rat\n",
        "        row, col, valid = self.state\n",
        "        canvas[row, col] = rat_mark\n",
        "        return canvas\n",
        "\n",
        "    def game_status(self):\n",
        "        if self.total_reward < self.min_reward:\n",
        "            return 'lose'\n",
        "        rat_row, rat_col, mode = self.state\n",
        "        nrows, ncols = self.maze.shape\n",
        "        if rat_row == nrows-1 and rat_col == ncols-1:\n",
        "            return 'win'\n",
        "\n",
        "        return 'not_over'\n",
        "\n",
        "    def valid_actions(self, cell=None):\n",
        "        if cell is None:\n",
        "            row, col, mode = self.state\n",
        "        else:\n",
        "            row, col = cell\n",
        "        actions = [0, 1, 2, 3]\n",
        "        nrows, ncols = self.maze.shape\n",
        "        if row == 0:\n",
        "            actions.remove(1)\n",
        "        elif row == nrows-1:\n",
        "            actions.remove(3)\n",
        "\n",
        "        if col == 0:\n",
        "            actions.remove(0)\n",
        "        elif col == ncols-1:\n",
        "            actions.remove(2)\n",
        "\n",
        "        if row>0 and self.maze[row-1,col] == 0.0:\n",
        "            actions.remove(1)\n",
        "        if row<nrows-1 and self.maze[row+1,col] == 0.0:\n",
        "            actions.remove(3)\n",
        "\n",
        "        if col>0 and self.maze[row,col-1] == 0.0:\n",
        "            actions.remove(0)\n",
        "        if col<ncols-1 and self.maze[row,col+1] == 0.0:\n",
        "            actions.remove(2)\n",
        "\n",
        "        return actions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEgvv0QHAcqO"
      },
      "source": [
        "def show(qmaze):\n",
        "    plt.grid('on')\n",
        "    nrows, ncols = qmaze.maze.shape\n",
        "    ax = plt.gca()\n",
        "    ax.set_xticks(np.arange(0.5, nrows, 1))\n",
        "    ax.set_yticks(np.arange(0.5, ncols, 1))\n",
        "    ax.set_xticklabels([])\n",
        "    ax.set_yticklabels([])\n",
        "    canvas = np.copy(qmaze.maze)\n",
        "    for row,col in qmaze.visited:\n",
        "        canvas[row,col] = 0.6\n",
        "    rat_row, rat_col, _ = qmaze.state\n",
        "    canvas[rat_row, rat_col] = 0.3   # rat cell\n",
        "    canvas[nrows-1, ncols-1] = 0.9 # cheese cell\n",
        "    img = plt.imshow(canvas, interpolation='none', cmap='gray')\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PTTplH_Am9F"
      },
      "source": [
        "## Primeiro Labirinto\n",
        "# maze = np.array([\n",
        "#     [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
        "#     [ 1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.],\n",
        "#     [ 1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.],\n",
        "#     [ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n",
        "#     [ 1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
        "#     [ 1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.],\n",
        "#     [ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n",
        "#     [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.]\n",
        "# ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXYrCEK_EZ-U"
      },
      "source": [
        "## Segundo Labirinto\n",
        "maze = np.array([\n",
        "    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
        "    [ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n",
        "    [ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n",
        "    [ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  1.],\n",
        "    [ 1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.],\n",
        "    [ 1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
        "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
        "    [ 1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],\n",
        "    [ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.],\n",
        "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.]\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTO46kedArMF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "91e94e39-f294-4b5b-9856-51453e74e828"
      },
      "source": [
        "qmaze = Qmaze(maze)\n",
        "canvas, reward, game_over = qmaze.act(DOWN)\n",
        "print(\"reward=\", reward)\n",
        "show(qmaze)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reward= -0.04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc80704bb50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAGfklEQVR4nO3dMU6UaxTH4fPdkFjIjSgmEw39LGBYAHZ2NBp3cDcAnXEDhhW4AlrjApgFDIUljbEgMSY2JlhZfLdAcm8BV+b6vsIfnif5qjEnJ4M/GJrDMI5jAdffH1e9AHA5YoUQYoUQYoUQYoUQYoUQK8v849XV1XF9fb3tAisr9eHDh6Yzq6oePXpUjx8/bj7327dvdffu3Yi5Sbumze2168ePH+vLly/Dea8tFev6+nq9fPmyzVY/PHjwoJ4/f950ZlXVzs5O7ezsNJ87n89ra2srYm7Srmlze+26ubl54Ws+BkMIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUKIpW4wff36td69e9d0ge3t7erx93bm83nzmYmG4dzbW79kb2+vy/0h/tvws1CGYfirqv6qqrp///7s9evXTRdYW1urhw8fNp1ZVXVyclKrq6u3eu7JyUkdHR01nVlVtbGxUZPJpPnctPe2x667u7u1WCz+33XDcRzfVNWbqqq1tbXx7du3TZfb3t6uZ8+eNZ1ZlXUpr9fc+Xxeu7u7TWdWnf5kffHiRfO5ae/t7/504XdWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCLHUwbTJZDLb399vukDSkay0uQ6m9Zt7FQfTahzHSz+z2Wxs7eDgoPlMc/+ZWVXNn729vea7nu2bMrfXrj8aO7c/H4MhhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghxFKxHh4e1jAMTZ8eM8/m9tBz3x4zL7rn8yvPbDaL+prdFEtdN7x3797s1atXTRfY2Nio4+PjpjPP5va4wPf58+du+7ae2/MK4W2/mnjtrxtWp0t5veb20HPflPfA1UTXDYH/IFYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIIVYIsVSss9msy6W81jPP5va4wNdrX04lXY787e/Nz/6j/Pu64WQyme3v7zddoNeVuF4X+KbTaZd9e1xNTLxueNsvRza7bvjj8lpTva7E9brA12tf1w37XrpMeW9dN4QbQKwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQYuWqFyDT2OEi43w+j5k7n8+bzrsM1w2X5Lph369Zytxeu7pu6LphUz2/Zilze+3quiHcAGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEGKFEDf6YNptn5u0a9pcB9PMvfYzze03cxwdTIMbQawQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQwnXDGzy3565HR0fN525sbNTx8XHE3F677u7u1jiOrhvetrk9d62q5s/e3l7M3F67nibpuiFEEyuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEuBaxDsPQ/Dk8PLz1c3vuetGdoF95ZrNZzNyeu17YyXgNrhve9kt5veb23HUymTSf63Lk6XXDxWJxfa8bVshFu7S5PXftweXIcfzRmOuGkEysEEKsEEKsEEKsEEKsEEKsEEKsEEKsEEKsEEKsEEKsEEKsEEKsEEKsEEKsEEKsEEKsEEKsEGLlqheoOr0D1dp8Pr/1c3vu2sswnH8r7FccHBw0n1lV9enTp+Yzv3//fuFr1+K6YcpFu7S5Sbueze1x6XI6nXZ5b+/cudN0ZtXpdcP379+f+x3rp7H+2+bm5rhYLJotVnX6XXpra6vpTHP7zew998mTJ83nHhwcdHlvp9Np05lVVU+fPr0wVr+zQgixQgixQgixQgixQgixQgixQgixQgixQgixQgixQgixQgixQgixQgixQgixQgixQgixQgixQoilDqZV1bSqWl+0elhVXxrPNLffTHP7zayqmo7j+Od5Lyx1MK2HYRgW4zhumtt+btKuaXOvYlcfgyGEWCHEdYj1jbnd5ibtmjb3t+965b+zApdzHX6yApcgVgghVgghVgghVgjxN0I65FOEm1izAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QOkRblSA3IH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "94f7f6c5-1ba8-424d-f3e4-76b8d5cca6ce"
      },
      "source": [
        "qmaze.act(DOWN)  # move down\n",
        "qmaze.act(RIGHT)  # move right\n",
        "qmaze.act(RIGHT)  # move right\n",
        "qmaze.act(RIGHT)  # move right\n",
        "qmaze.act(UP)  # move up\n",
        "show(qmaze)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc806b2f850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qj1TKfnA9qu"
      },
      "source": [
        "def play_game(model, qmaze, rat_cell):\n",
        "    qmaze.reset(rat_cell)\n",
        "    envstate = qmaze.observe()\n",
        "    while True:\n",
        "        prev_envstate = envstate\n",
        "        # get next action\n",
        "        q = model.predict(prev_envstate)\n",
        "        action = np.argmax(q[0])\n",
        "\n",
        "        # apply action, get rewards and new state\n",
        "        envstate, reward, game_status = qmaze.act(action)\n",
        "        if game_status == 'win':\n",
        "            return True\n",
        "        elif game_status == 'lose':\n",
        "            return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw53DdHQBKF0"
      },
      "source": [
        "def completion_check(model, qmaze):\n",
        "    for cell in qmaze.free_cells:\n",
        "        if not qmaze.valid_actions(cell):\n",
        "            return False\n",
        "        if not play_game(model, qmaze, cell):\n",
        "            return False\n",
        "    return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm9WstgwBgjg"
      },
      "source": [
        "class Experience(object):\n",
        "    def __init__(self, model, max_memory=100, discount=0.95):\n",
        "        self.model = model\n",
        "        self.max_memory = max_memory\n",
        "        self.discount = discount\n",
        "        self.memory = list()\n",
        "        self.num_actions = model.output_shape[-1]\n",
        "\n",
        "    def remember(self, episode):\n",
        "        # episode = [envstate, action, reward, envstate_next, game_over]\n",
        "        # memory[i] = episode\n",
        "        # envstate == flattened 1d maze cells info, including rat cell (see method: observe)\n",
        "        self.memory.append(episode)\n",
        "        if len(self.memory) > self.max_memory:\n",
        "            del self.memory[0]\n",
        "\n",
        "    def predict(self, envstate):\n",
        "        return self.model.predict(envstate)[0]\n",
        "\n",
        "    def get_data(self, data_size=10):\n",
        "        env_size = self.memory[0][0].shape[1]   # envstate 1d size (1st element of episode)\n",
        "        mem_size = len(self.memory)\n",
        "        data_size = min(mem_size, data_size)\n",
        "        inputs = np.zeros((data_size, env_size))\n",
        "        targets = np.zeros((data_size, self.num_actions))\n",
        "        for i, j in enumerate(np.random.choice(range(mem_size), data_size, replace=False)):\n",
        "            envstate, action, reward, envstate_next, game_over = self.memory[j]\n",
        "            inputs[i] = envstate\n",
        "            # There should be no target values for actions not taken.\n",
        "            targets[i] = self.predict(envstate)\n",
        "            # Q_sa = derived policy = max quality env/action = max_a' Q(s', a')\n",
        "            Q_sa = np.max(self.predict(envstate_next))\n",
        "            if game_over:\n",
        "                targets[i, action] = reward\n",
        "            else:\n",
        "                # reward + gamma * max_a' Q(s', a')\n",
        "                targets[i, action] = reward + self.discount * Q_sa\n",
        "        return inputs, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QvK92JaBiL7"
      },
      "source": [
        "def qtrain(model, maze, **opt):\n",
        "    global epsilon\n",
        "    n_epoch = opt.get('n_epoch', 15000)\n",
        "    max_memory = opt.get('max_memory', 1000)\n",
        "    data_size = opt.get('data_size', 50)\n",
        "    weights_file = opt.get('weights_file', \"\")\n",
        "    name = opt.get('name', 'model')\n",
        "    start_time = datetime.datetime.now()\n",
        "\n",
        "    # If you want to continue training from a previous model,\n",
        "    # just supply the h5 file name to weights_file option\n",
        "    if weights_file:\n",
        "        print(\"loading weights from file: %s\" % (weights_file,))\n",
        "        model.load_weights(weights_file)\n",
        "\n",
        "    # Construct environment/game from numpy array: maze (see above)\n",
        "    qmaze = Qmaze(maze)\n",
        "\n",
        "    # Initialize experience replay object\n",
        "    experience = Experience(model, max_memory=max_memory)\n",
        "\n",
        "    win_history = []   # history of win/lose game\n",
        "    n_free_cells = len(qmaze.free_cells)\n",
        "    hsize = qmaze.maze.size//2   # history window size\n",
        "    win_rate = 0.0\n",
        "    imctr = 1\n",
        "\n",
        "    for epoch in range(n_epoch):\n",
        "        loss = 0.0\n",
        "        rat_cell = random.choice(qmaze.free_cells)\n",
        "        qmaze.reset(rat_cell)\n",
        "        game_over = False\n",
        "\n",
        "        # get initial envstate (1d flattened canvas)\n",
        "        envstate = qmaze.observe()\n",
        "\n",
        "        n_episodes = 0\n",
        "        while not game_over:\n",
        "            valid_actions = qmaze.valid_actions()\n",
        "            if not valid_actions: break\n",
        "            prev_envstate = envstate\n",
        "            # Get next action\n",
        "            if np.random.rand() < epsilon:\n",
        "                action = random.choice(valid_actions)\n",
        "            else:\n",
        "                action = np.argmax(experience.predict(prev_envstate))\n",
        "\n",
        "            # Apply action, get reward and new envstate\n",
        "            envstate, reward, game_status = qmaze.act(action)\n",
        "            if game_status == 'win':\n",
        "                win_history.append(1)\n",
        "                game_over = True\n",
        "            elif game_status == 'lose':\n",
        "                win_history.append(0)\n",
        "                game_over = True\n",
        "            else:\n",
        "                game_over = False\n",
        "\n",
        "            # Store episode (experience)\n",
        "            episode = [prev_envstate, action, reward, envstate, game_over]\n",
        "            experience.remember(episode)\n",
        "            n_episodes += 1\n",
        "\n",
        "            # Train neural network model\n",
        "            inputs, targets = experience.get_data(data_size=data_size)\n",
        "            h = model.fit(\n",
        "                inputs,\n",
        "                targets,\n",
        "                epochs=8,\n",
        "                batch_size=16,\n",
        "                verbose=0,\n",
        "            )\n",
        "            loss = model.evaluate(inputs, targets, verbose=0)\n",
        "\n",
        "        if len(win_history) > hsize:\n",
        "            win_rate = sum(win_history[-hsize:]) / hsize\n",
        "    \n",
        "        dt = datetime.datetime.now() - start_time\n",
        "        t = format_time(dt.total_seconds())\n",
        "        template = \"Epoch: {:03d}/{:d} | Loss: {:.4f} | Episodes: {:d} | Win count: {:d} | Win rate: {:.3f} | time: {}\"\n",
        "        print(template.format(epoch, n_epoch-1, loss, n_episodes, sum(win_history), win_rate, t))\n",
        "        # we simply check if training has exhausted all free cells and if in all\n",
        "        # cases the agent won\n",
        "        if win_rate > 0.9 : epsilon = 0.05\n",
        "        if sum(win_history[-hsize:]) == hsize and completion_check(model, qmaze):\n",
        "            print(\"Reached 100%% win rate at epoch: %d\" % (epoch,))\n",
        "            break\n",
        "\n",
        "    # Save trained model weights and architecture, this will be used by the visualization code\n",
        "    h5file = name + \".h5\"\n",
        "    json_file = name + \".json\"\n",
        "    model.save_weights(h5file, overwrite=True)\n",
        "    with open(json_file, \"w\") as outfile:\n",
        "        json.dump(model.to_json(), outfile)\n",
        "    end_time = datetime.datetime.now()\n",
        "    dt = datetime.datetime.now() - start_time\n",
        "    seconds = dt.total_seconds()\n",
        "    t = format_time(seconds)\n",
        "    print('files: %s, %s' % (h5file, json_file))\n",
        "    print(\"n_epoch: %d, max_mem: %d, data: %d, time: %s\" % (epoch, max_memory, data_size, t))\n",
        "    return seconds\n",
        "\n",
        "# This is a small utility for printing readable time strings:\n",
        "def format_time(seconds):\n",
        "    if seconds < 400:\n",
        "        s = float(seconds)\n",
        "        return \"%.1f seconds\" % (s,)\n",
        "    elif seconds < 4000:\n",
        "        m = seconds / 60.0\n",
        "        return \"%.2f minutes\" % (m,)\n",
        "    else:\n",
        "        h = seconds / 3600.0\n",
        "        return \"%.2f hours\" % (h,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W6tHgyyBzrr"
      },
      "source": [
        "def build_model(maze, lr=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(maze.size, input_shape=(maze.size,)))\n",
        "    model.add(PReLU())\n",
        "    model.add(Dense(maze.size))\n",
        "    model.add(PReLU())\n",
        "    model.add(Dense(num_actions))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUWPPKi6B5tj"
      },
      "source": [
        "## Primeiro Labirinto\n",
        "# maze =  np.array([\n",
        "#     [ 1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
        "#     [ 1.,  1.,  1.,  0.,  0.,  1.,  0.],\n",
        "#     [ 0.,  0.,  0.,  1.,  1.,  1.,  0.],\n",
        "#     [ 1.,  1.,  1.,  1.,  0.,  0.,  1.],\n",
        "#     [ 1.,  0.,  0.,  0.,  1.,  1.,  1.],\n",
        "#     [ 1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
        "#     [ 1.,  1.,  1.,  0.,  1.,  1.,  1.]\n",
        "# ])\n",
        "\n",
        "# qmaze = Qmaze(maze)\n",
        "# show(qmaze)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXIvaUxDE2tE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "23440068-6b78-4cba-a35a-8344e4bc62b3"
      },
      "source": [
        "## Segundo Labirinto\n",
        "maze = np.array([\n",
        "    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
        "    [ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n",
        "    [ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n",
        "    [ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  1.],\n",
        "    [ 1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.],\n",
        "    [ 1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
        "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
        "    [ 1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],\n",
        "    [ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.],\n",
        "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.]\n",
        "])\n",
        "qmaze = Qmaze(maze)\n",
        "show(qmaze)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc806aca410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK9lCeTACAcy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d97606-dee3-4d5b-d25e-9fdccde34a62"
      },
      "source": [
        "model = build_model(maze)\n",
        "qtrain(model, maze, epochs=1000, max_memory=8*maze.size, data_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 000/14999 | Loss: 0.0016 | Episodes: 129 | Win count: 1 | Win rate: 0.000 | time: 269.1 seconds\n",
            "Epoch: 001/14999 | Loss: 0.0048 | Episodes: 217 | Win count: 1 | Win rate: 0.000 | time: 12.46 minutes\n",
            "Epoch: 002/14999 | Loss: 0.0011 | Episodes: 147 | Win count: 2 | Win rate: 0.000 | time: 17.86 minutes\n",
            "Epoch: 003/14999 | Loss: 0.1075 | Episodes: 224 | Win count: 2 | Win rate: 0.000 | time: 26.03 minutes\n",
            "Epoch: 004/14999 | Loss: 0.0009 | Episodes: 79 | Win count: 3 | Win rate: 0.000 | time: 28.93 minutes\n",
            "Epoch: 005/14999 | Loss: 0.0462 | Episodes: 77 | Win count: 4 | Win rate: 0.000 | time: 31.76 minutes\n",
            "Epoch: 006/14999 | Loss: 0.0065 | Episodes: 222 | Win count: 4 | Win rate: 0.000 | time: 39.89 minutes\n",
            "Epoch: 007/14999 | Loss: 0.0021 | Episodes: 215 | Win count: 4 | Win rate: 0.000 | time: 47.84 minutes\n",
            "Epoch: 008/14999 | Loss: 0.0047 | Episodes: 144 | Win count: 5 | Win rate: 0.000 | time: 53.13 minutes\n",
            "Epoch: 009/14999 | Loss: 0.0204 | Episodes: 39 | Win count: 6 | Win rate: 0.000 | time: 54.55 minutes\n",
            "Epoch: 010/14999 | Loss: 0.0135 | Episodes: 24 | Win count: 7 | Win rate: 0.000 | time: 55.42 minutes\n",
            "Epoch: 011/14999 | Loss: 0.0014 | Episodes: 13 | Win count: 8 | Win rate: 0.000 | time: 55.89 minutes\n",
            "Epoch: 012/14999 | Loss: 0.0307 | Episodes: 83 | Win count: 9 | Win rate: 0.000 | time: 58.88 minutes\n",
            "Epoch: 013/14999 | Loss: 0.0083 | Episodes: 102 | Win count: 10 | Win rate: 0.000 | time: 62.57 minutes\n",
            "Epoch: 014/14999 | Loss: 0.0030 | Episodes: 64 | Win count: 11 | Win rate: 0.000 | time: 64.88 minutes\n",
            "Epoch: 015/14999 | Loss: 0.0049 | Episodes: 17 | Win count: 12 | Win rate: 0.000 | time: 65.50 minutes\n",
            "Epoch: 016/14999 | Loss: 0.0044 | Episodes: 17 | Win count: 13 | Win rate: 0.000 | time: 66.13 minutes\n",
            "Epoch: 017/14999 | Loss: 0.0316 | Episodes: 25 | Win count: 14 | Win rate: 0.000 | time: 1.12 hours\n",
            "Epoch: 018/14999 | Loss: 0.0028 | Episodes: 120 | Win count: 15 | Win rate: 0.000 | time: 1.19 hours\n",
            "Epoch: 019/14999 | Loss: 0.0043 | Episodes: 16 | Win count: 16 | Win rate: 0.000 | time: 1.20 hours\n",
            "Epoch: 020/14999 | Loss: 0.0046 | Episodes: 98 | Win count: 17 | Win rate: 0.000 | time: 1.26 hours\n",
            "Epoch: 021/14999 | Loss: 0.0031 | Episodes: 39 | Win count: 18 | Win rate: 0.000 | time: 1.28 hours\n",
            "Epoch: 022/14999 | Loss: 0.0122 | Episodes: 33 | Win count: 19 | Win rate: 0.000 | time: 1.30 hours\n",
            "Epoch: 023/14999 | Loss: 0.0041 | Episodes: 15 | Win count: 20 | Win rate: 0.000 | time: 1.31 hours\n",
            "Epoch: 024/14999 | Loss: 0.0083 | Episodes: 8 | Win count: 21 | Win rate: 0.000 | time: 1.32 hours\n",
            "Epoch: 025/14999 | Loss: 0.0070 | Episodes: 216 | Win count: 21 | Win rate: 0.000 | time: 1.45 hours\n",
            "Epoch: 026/14999 | Loss: 0.0069 | Episodes: 23 | Win count: 22 | Win rate: 0.000 | time: 1.46 hours\n",
            "Epoch: 027/14999 | Loss: 0.0028 | Episodes: 123 | Win count: 23 | Win rate: 0.000 | time: 1.54 hours\n",
            "Epoch: 028/14999 | Loss: 0.0033 | Episodes: 215 | Win count: 23 | Win rate: 0.000 | time: 1.67 hours\n",
            "Epoch: 029/14999 | Loss: 0.0027 | Episodes: 24 | Win count: 24 | Win rate: 0.000 | time: 1.68 hours\n",
            "Epoch: 030/14999 | Loss: 0.0055 | Episodes: 70 | Win count: 25 | Win rate: 0.000 | time: 1.73 hours\n",
            "Epoch: 031/14999 | Loss: 0.0033 | Episodes: 16 | Win count: 26 | Win rate: 0.000 | time: 1.74 hours\n",
            "Epoch: 032/14999 | Loss: 0.0040 | Episodes: 123 | Win count: 27 | Win rate: 0.000 | time: 1.81 hours\n",
            "Epoch: 033/14999 | Loss: 0.0037 | Episodes: 1 | Win count: 28 | Win rate: 0.000 | time: 1.81 hours\n",
            "Epoch: 034/14999 | Loss: 0.0030 | Episodes: 34 | Win count: 29 | Win rate: 0.000 | time: 1.83 hours\n",
            "Epoch: 035/14999 | Loss: 0.0033 | Episodes: 50 | Win count: 30 | Win rate: 0.000 | time: 1.86 hours\n",
            "Epoch: 036/14999 | Loss: 0.0078 | Episodes: 51 | Win count: 31 | Win rate: 0.000 | time: 1.89 hours\n",
            "Epoch: 037/14999 | Loss: 0.0026 | Episodes: 35 | Win count: 32 | Win rate: 0.000 | time: 1.91 hours\n",
            "Epoch: 038/14999 | Loss: 0.0055 | Episodes: 20 | Win count: 33 | Win rate: 0.000 | time: 1.93 hours\n",
            "Epoch: 039/14999 | Loss: 0.0037 | Episodes: 21 | Win count: 34 | Win rate: 0.000 | time: 1.94 hours\n",
            "Epoch: 040/14999 | Loss: 0.0077 | Episodes: 14 | Win count: 35 | Win rate: 0.000 | time: 1.95 hours\n",
            "Epoch: 041/14999 | Loss: 0.0044 | Episodes: 20 | Win count: 36 | Win rate: 0.000 | time: 1.96 hours\n",
            "Epoch: 042/14999 | Loss: 0.0037 | Episodes: 30 | Win count: 37 | Win rate: 0.000 | time: 1.98 hours\n",
            "Epoch: 043/14999 | Loss: 0.0103 | Episodes: 43 | Win count: 38 | Win rate: 0.000 | time: 2.01 hours\n",
            "Epoch: 044/14999 | Loss: 0.0030 | Episodes: 86 | Win count: 39 | Win rate: 0.000 | time: 2.06 hours\n",
            "Epoch: 045/14999 | Loss: 0.0075 | Episodes: 115 | Win count: 40 | Win rate: 0.000 | time: 2.13 hours\n",
            "Epoch: 046/14999 | Loss: 0.0033 | Episodes: 37 | Win count: 41 | Win rate: 0.000 | time: 2.15 hours\n",
            "Epoch: 047/14999 | Loss: 0.0046 | Episodes: 38 | Win count: 42 | Win rate: 0.000 | time: 2.17 hours\n",
            "Epoch: 048/14999 | Loss: 0.0017 | Episodes: 17 | Win count: 43 | Win rate: 0.000 | time: 2.19 hours\n",
            "Epoch: 049/14999 | Loss: 0.0078 | Episodes: 22 | Win count: 44 | Win rate: 0.000 | time: 2.20 hours\n",
            "Epoch: 050/14999 | Loss: 0.0014 | Episodes: 26 | Win count: 45 | Win rate: 0.880 | time: 2.21 hours\n",
            "Epoch: 051/14999 | Loss: 0.0015 | Episodes: 33 | Win count: 46 | Win rate: 0.900 | time: 2.23 hours\n",
            "Epoch: 052/14999 | Loss: 0.0019 | Episodes: 1 | Win count: 47 | Win rate: 0.900 | time: 2.23 hours\n",
            "Epoch: 053/14999 | Loss: 0.0072 | Episodes: 161 | Win count: 48 | Win rate: 0.920 | time: 2.33 hours\n",
            "Epoch: 054/14999 | Loss: 0.0028 | Episodes: 42 | Win count: 49 | Win rate: 0.920 | time: 2.36 hours\n",
            "Epoch: 055/14999 | Loss: 0.0037 | Episodes: 22 | Win count: 50 | Win rate: 0.920 | time: 2.37 hours\n",
            "Epoch: 056/14999 | Loss: 0.0013 | Episodes: 10 | Win count: 51 | Win rate: 0.940 | time: 2.38 hours\n",
            "Epoch: 057/14999 | Loss: 0.0017 | Episodes: 21 | Win count: 52 | Win rate: 0.960 | time: 2.39 hours\n",
            "Epoch: 058/14999 | Loss: 0.0016 | Episodes: 18 | Win count: 53 | Win rate: 0.960 | time: 2.40 hours\n",
            "Epoch: 059/14999 | Loss: 0.0010 | Episodes: 30 | Win count: 54 | Win rate: 0.960 | time: 2.42 hours\n",
            "Epoch: 060/14999 | Loss: 0.0019 | Episodes: 1 | Win count: 55 | Win rate: 0.960 | time: 2.42 hours\n",
            "Epoch: 061/14999 | Loss: 0.0010 | Episodes: 26 | Win count: 56 | Win rate: 0.960 | time: 2.44 hours\n",
            "Epoch: 062/14999 | Loss: 0.0012 | Episodes: 35 | Win count: 57 | Win rate: 0.960 | time: 2.46 hours\n",
            "Epoch: 063/14999 | Loss: 0.0006 | Episodes: 21 | Win count: 58 | Win rate: 0.960 | time: 2.47 hours\n",
            "Epoch: 064/14999 | Loss: 0.0021 | Episodes: 20 | Win count: 59 | Win rate: 0.960 | time: 2.48 hours\n",
            "Epoch: 065/14999 | Loss: 0.0009 | Episodes: 18 | Win count: 60 | Win rate: 0.960 | time: 2.49 hours\n",
            "Epoch: 066/14999 | Loss: 0.0011 | Episodes: 31 | Win count: 61 | Win rate: 0.960 | time: 2.51 hours\n",
            "Epoch: 067/14999 | Loss: 0.0012 | Episodes: 15 | Win count: 62 | Win rate: 0.960 | time: 2.52 hours\n",
            "Epoch: 068/14999 | Loss: 0.0011 | Episodes: 46 | Win count: 63 | Win rate: 0.960 | time: 2.55 hours\n",
            "Epoch: 069/14999 | Loss: 0.0002 | Episodes: 27 | Win count: 64 | Win rate: 0.960 | time: 2.57 hours\n",
            "Epoch: 070/14999 | Loss: 0.0014 | Episodes: 1 | Win count: 65 | Win rate: 0.960 | time: 2.57 hours\n",
            "Epoch: 071/14999 | Loss: 0.0003 | Episodes: 22 | Win count: 66 | Win rate: 0.960 | time: 2.58 hours\n",
            "Epoch: 072/14999 | Loss: 0.0005 | Episodes: 28 | Win count: 67 | Win rate: 0.960 | time: 2.60 hours\n",
            "Epoch: 073/14999 | Loss: 0.0007 | Episodes: 36 | Win count: 68 | Win rate: 0.960 | time: 2.62 hours\n",
            "Epoch: 074/14999 | Loss: 0.0006 | Episodes: 44 | Win count: 69 | Win rate: 0.960 | time: 2.65 hours\n",
            "Epoch: 075/14999 | Loss: 0.0009 | Episodes: 7 | Win count: 70 | Win rate: 0.980 | time: 2.65 hours\n",
            "Epoch: 076/14999 | Loss: 0.0017 | Episodes: 41 | Win count: 71 | Win rate: 0.980 | time: 2.68 hours\n",
            "Epoch: 077/14999 | Loss: 0.0028 | Episodes: 5 | Win count: 72 | Win rate: 0.980 | time: 2.68 hours\n",
            "Epoch: 078/14999 | Loss: 0.0028 | Episodes: 57 | Win count: 73 | Win rate: 1.000 | time: 2.71 hours\n",
            "Epoch: 079/14999 | Loss: 0.0011 | Episodes: 42 | Win count: 74 | Win rate: 1.000 | time: 2.75 hours\n",
            "Epoch: 080/14999 | Loss: 0.0010 | Episodes: 62 | Win count: 75 | Win rate: 1.000 | time: 2.79 hours\n",
            "Epoch: 081/14999 | Loss: 0.0041 | Episodes: 51 | Win count: 76 | Win rate: 1.000 | time: 2.82 hours\n",
            "Epoch: 082/14999 | Loss: 0.0036 | Episodes: 15 | Win count: 77 | Win rate: 1.000 | time: 2.83 hours\n",
            "Epoch: 083/14999 | Loss: 0.0003 | Episodes: 23 | Win count: 78 | Win rate: 1.000 | time: 2.85 hours\n",
            "Epoch: 084/14999 | Loss: 0.0009 | Episodes: 44 | Win count: 79 | Win rate: 1.000 | time: 2.87 hours\n",
            "Epoch: 085/14999 | Loss: 0.0011 | Episodes: 8 | Win count: 80 | Win rate: 1.000 | time: 2.88 hours\n",
            "Epoch: 086/14999 | Loss: 0.0011 | Episodes: 21 | Win count: 81 | Win rate: 1.000 | time: 2.90 hours\n",
            "Epoch: 087/14999 | Loss: 0.0010 | Episodes: 22 | Win count: 82 | Win rate: 1.000 | time: 2.92 hours\n",
            "Epoch: 088/14999 | Loss: 0.0004 | Episodes: 33 | Win count: 83 | Win rate: 1.000 | time: 2.94 hours\n",
            "Epoch: 089/14999 | Loss: 0.0024 | Episodes: 21 | Win count: 84 | Win rate: 1.000 | time: 2.96 hours\n",
            "Epoch: 090/14999 | Loss: 0.0007 | Episodes: 43 | Win count: 85 | Win rate: 1.000 | time: 2.99 hours\n",
            "Epoch: 091/14999 | Loss: 0.0008 | Episodes: 14 | Win count: 86 | Win rate: 1.000 | time: 3.00 hours\n",
            "Epoch: 092/14999 | Loss: 0.0012 | Episodes: 52 | Win count: 87 | Win rate: 1.000 | time: 3.04 hours\n",
            "Epoch: 093/14999 | Loss: 0.0006 | Episodes: 17 | Win count: 88 | Win rate: 1.000 | time: 3.05 hours\n",
            "Epoch: 094/14999 | Loss: 0.0005 | Episodes: 13 | Win count: 89 | Win rate: 1.000 | time: 3.07 hours\n",
            "Epoch: 095/14999 | Loss: 0.0006 | Episodes: 27 | Win count: 90 | Win rate: 1.000 | time: 3.09 hours\n",
            "Epoch: 096/14999 | Loss: 0.0018 | Episodes: 29 | Win count: 91 | Win rate: 1.000 | time: 3.11 hours\n",
            "Epoch: 097/14999 | Loss: 0.0007 | Episodes: 36 | Win count: 92 | Win rate: 1.000 | time: 3.13 hours\n",
            "Epoch: 098/14999 | Loss: 0.0017 | Episodes: 67 | Win count: 93 | Win rate: 1.000 | time: 3.18 hours\n",
            "Epoch: 099/14999 | Loss: 0.0009 | Episodes: 35 | Win count: 94 | Win rate: 1.000 | time: 3.21 hours\n",
            "Epoch: 100/14999 | Loss: 0.0002 | Episodes: 22 | Win count: 95 | Win rate: 1.000 | time: 3.22 hours\n",
            "Epoch: 101/14999 | Loss: 0.0015 | Episodes: 15 | Win count: 96 | Win rate: 1.000 | time: 3.23 hours\n",
            "Epoch: 102/14999 | Loss: 0.0010 | Episodes: 38 | Win count: 97 | Win rate: 1.000 | time: 3.26 hours\n",
            "Epoch: 103/14999 | Loss: 0.0005 | Episodes: 33 | Win count: 98 | Win rate: 1.000 | time: 3.28 hours\n",
            "Epoch: 104/14999 | Loss: 0.0009 | Episodes: 15 | Win count: 99 | Win rate: 1.000 | time: 3.29 hours\n",
            "Epoch: 105/14999 | Loss: 0.0005 | Episodes: 45 | Win count: 100 | Win rate: 1.000 | time: 3.32 hours\n",
            "Epoch: 106/14999 | Loss: 0.0016 | Episodes: 21 | Win count: 101 | Win rate: 1.000 | time: 3.34 hours\n",
            "Epoch: 107/14999 | Loss: 0.0010 | Episodes: 31 | Win count: 102 | Win rate: 1.000 | time: 3.36 hours\n",
            "Epoch: 108/14999 | Loss: 0.0026 | Episodes: 3 | Win count: 103 | Win rate: 1.000 | time: 3.36 hours\n",
            "Epoch: 109/14999 | Loss: 0.0005 | Episodes: 38 | Win count: 104 | Win rate: 1.000 | time: 3.38 hours\n",
            "Epoch: 110/14999 | Loss: 0.0004 | Episodes: 25 | Win count: 105 | Win rate: 1.000 | time: 3.40 hours\n",
            "Epoch: 111/14999 | Loss: 0.0013 | Episodes: 56 | Win count: 106 | Win rate: 1.000 | time: 3.44 hours\n",
            "Epoch: 112/14999 | Loss: 0.0015 | Episodes: 21 | Win count: 107 | Win rate: 1.000 | time: 3.45 hours\n",
            "Epoch: 113/14999 | Loss: 0.0005 | Episodes: 19 | Win count: 108 | Win rate: 1.000 | time: 3.47 hours\n",
            "Epoch: 114/14999 | Loss: 0.0006 | Episodes: 19 | Win count: 109 | Win rate: 1.000 | time: 3.48 hours\n",
            "Epoch: 115/14999 | Loss: 0.0004 | Episodes: 37 | Win count: 110 | Win rate: 1.000 | time: 3.50 hours\n",
            "Epoch: 116/14999 | Loss: 0.0009 | Episodes: 17 | Win count: 111 | Win rate: 1.000 | time: 3.52 hours\n",
            "Epoch: 117/14999 | Loss: 0.0017 | Episodes: 50 | Win count: 112 | Win rate: 1.000 | time: 3.55 hours\n",
            "Epoch: 118/14999 | Loss: 0.0015 | Episodes: 13 | Win count: 113 | Win rate: 1.000 | time: 3.56 hours\n",
            "Epoch: 119/14999 | Loss: 0.0011 | Episodes: 13 | Win count: 114 | Win rate: 1.000 | time: 3.57 hours\n",
            "Epoch: 120/14999 | Loss: 0.0017 | Episodes: 2 | Win count: 115 | Win rate: 1.000 | time: 3.57 hours\n",
            "Epoch: 121/14999 | Loss: 0.0075 | Episodes: 6 | Win count: 116 | Win rate: 1.000 | time: 3.58 hours\n",
            "Epoch: 122/14999 | Loss: 0.0017 | Episodes: 10 | Win count: 117 | Win rate: 1.000 | time: 3.58 hours\n",
            "Epoch: 123/14999 | Loss: 0.0015 | Episodes: 19 | Win count: 118 | Win rate: 1.000 | time: 3.60 hours\n",
            "Epoch: 124/14999 | Loss: 0.0010 | Episodes: 22 | Win count: 119 | Win rate: 1.000 | time: 3.61 hours\n",
            "Epoch: 125/14999 | Loss: 0.0011 | Episodes: 23 | Win count: 120 | Win rate: 1.000 | time: 3.63 hours\n",
            "Epoch: 126/14999 | Loss: 0.0010 | Episodes: 31 | Win count: 121 | Win rate: 1.000 | time: 3.65 hours\n",
            "Epoch: 127/14999 | Loss: 0.0006 | Episodes: 26 | Win count: 122 | Win rate: 1.000 | time: 3.66 hours\n",
            "Epoch: 128/14999 | Loss: 0.0005 | Episodes: 67 | Win count: 123 | Win rate: 1.000 | time: 3.71 hours\n",
            "Epoch: 129/14999 | Loss: 0.0017 | Episodes: 7 | Win count: 124 | Win rate: 1.000 | time: 3.71 hours\n",
            "Epoch: 130/14999 | Loss: 0.0004 | Episodes: 9 | Win count: 125 | Win rate: 1.000 | time: 3.72 hours\n",
            "Epoch: 131/14999 | Loss: 0.0007 | Episodes: 12 | Win count: 126 | Win rate: 1.000 | time: 3.73 hours\n",
            "Epoch: 132/14999 | Loss: 0.0007 | Episodes: 29 | Win count: 127 | Win rate: 1.000 | time: 3.75 hours\n",
            "Epoch: 133/14999 | Loss: 0.0006 | Episodes: 4 | Win count: 128 | Win rate: 1.000 | time: 3.75 hours\n",
            "Epoch: 134/14999 | Loss: 0.0020 | Episodes: 15 | Win count: 129 | Win rate: 1.000 | time: 3.76 hours\n",
            "Epoch: 135/14999 | Loss: 0.0006 | Episodes: 23 | Win count: 130 | Win rate: 1.000 | time: 3.78 hours\n",
            "Epoch: 136/14999 | Loss: 0.0024 | Episodes: 39 | Win count: 131 | Win rate: 1.000 | time: 3.81 hours\n",
            "Epoch: 137/14999 | Loss: 0.0029 | Episodes: 4 | Win count: 132 | Win rate: 1.000 | time: 3.81 hours\n",
            "Epoch: 138/14999 | Loss: 0.0003 | Episodes: 78 | Win count: 133 | Win rate: 1.000 | time: 3.86 hours\n",
            "Epoch: 139/14999 | Loss: 0.0018 | Episodes: 46 | Win count: 134 | Win rate: 1.000 | time: 3.90 hours\n",
            "Epoch: 140/14999 | Loss: 0.0006 | Episodes: 17 | Win count: 135 | Win rate: 1.000 | time: 3.91 hours\n",
            "Epoch: 141/14999 | Loss: 0.0005 | Episodes: 16 | Win count: 136 | Win rate: 1.000 | time: 3.92 hours\n",
            "Epoch: 142/14999 | Loss: 0.0005 | Episodes: 40 | Win count: 137 | Win rate: 1.000 | time: 3.95 hours\n",
            "Epoch: 143/14999 | Loss: 0.0001 | Episodes: 27 | Win count: 138 | Win rate: 1.000 | time: 3.96 hours\n",
            "Epoch: 144/14999 | Loss: 0.0008 | Episodes: 13 | Win count: 139 | Win rate: 1.000 | time: 3.97 hours\n",
            "Epoch: 145/14999 | Loss: 0.0007 | Episodes: 48 | Win count: 140 | Win rate: 1.000 | time: 4.00 hours\n",
            "Epoch: 146/14999 | Loss: 0.0272 | Episodes: 55 | Win count: 141 | Win rate: 1.000 | time: 4.04 hours\n",
            "Epoch: 147/14999 | Loss: 0.0014 | Episodes: 36 | Win count: 142 | Win rate: 1.000 | time: 4.06 hours\n",
            "Epoch: 148/14999 | Loss: 0.0006 | Episodes: 38 | Win count: 143 | Win rate: 1.000 | time: 4.09 hours\n",
            "Epoch: 149/14999 | Loss: 0.0007 | Episodes: 45 | Win count: 144 | Win rate: 1.000 | time: 4.12 hours\n",
            "Epoch: 150/14999 | Loss: 0.0007 | Episodes: 38 | Win count: 145 | Win rate: 1.000 | time: 4.14 hours\n",
            "Epoch: 151/14999 | Loss: 0.0002 | Episodes: 3 | Win count: 146 | Win rate: 1.000 | time: 4.15 hours\n",
            "Epoch: 152/14999 | Loss: 0.0002 | Episodes: 32 | Win count: 147 | Win rate: 1.000 | time: 4.17 hours\n",
            "Epoch: 153/14999 | Loss: 0.0004 | Episodes: 44 | Win count: 148 | Win rate: 1.000 | time: 4.20 hours\n",
            "Epoch: 154/14999 | Loss: 0.0005 | Episodes: 22 | Win count: 149 | Win rate: 1.000 | time: 4.21 hours\n",
            "Epoch: 155/14999 | Loss: 0.0006 | Episodes: 34 | Win count: 150 | Win rate: 1.000 | time: 4.23 hours\n",
            "Epoch: 156/14999 | Loss: 0.0056 | Episodes: 57 | Win count: 151 | Win rate: 1.000 | time: 4.27 hours\n",
            "Epoch: 157/14999 | Loss: 0.0020 | Episodes: 77 | Win count: 152 | Win rate: 1.000 | time: 4.32 hours\n",
            "Epoch: 158/14999 | Loss: 0.0011 | Episodes: 24 | Win count: 153 | Win rate: 1.000 | time: 4.33 hours\n",
            "Epoch: 159/14999 | Loss: 0.0012 | Episodes: 15 | Win count: 154 | Win rate: 1.000 | time: 4.35 hours\n",
            "Epoch: 160/14999 | Loss: 0.0015 | Episodes: 8 | Win count: 155 | Win rate: 1.000 | time: 4.35 hours\n",
            "Epoch: 161/14999 | Loss: 0.0018 | Episodes: 21 | Win count: 156 | Win rate: 1.000 | time: 4.37 hours\n",
            "Epoch: 162/14999 | Loss: 0.0022 | Episodes: 8 | Win count: 157 | Win rate: 1.000 | time: 4.37 hours\n",
            "Epoch: 163/14999 | Loss: 0.0013 | Episodes: 7 | Win count: 158 | Win rate: 1.000 | time: 4.38 hours\n",
            "Epoch: 164/14999 | Loss: 0.0008 | Episodes: 23 | Win count: 159 | Win rate: 1.000 | time: 4.39 hours\n",
            "Epoch: 165/14999 | Loss: 0.0051 | Episodes: 22 | Win count: 160 | Win rate: 1.000 | time: 4.41 hours\n",
            "Epoch: 166/14999 | Loss: 0.0015 | Episodes: 17 | Win count: 161 | Win rate: 1.000 | time: 4.42 hours\n",
            "Epoch: 167/14999 | Loss: 0.0009 | Episodes: 34 | Win count: 162 | Win rate: 1.000 | time: 4.44 hours\n",
            "Epoch: 168/14999 | Loss: 0.0015 | Episodes: 18 | Win count: 163 | Win rate: 1.000 | time: 4.46 hours\n",
            "Epoch: 169/14999 | Loss: 0.0008 | Episodes: 35 | Win count: 164 | Win rate: 1.000 | time: 4.48 hours\n",
            "Epoch: 170/14999 | Loss: 0.0015 | Episodes: 34 | Win count: 165 | Win rate: 1.000 | time: 4.50 hours\n",
            "Epoch: 171/14999 | Loss: 0.0018 | Episodes: 17 | Win count: 166 | Win rate: 1.000 | time: 4.51 hours\n",
            "Epoch: 172/14999 | Loss: 0.0009 | Episodes: 30 | Win count: 167 | Win rate: 1.000 | time: 4.53 hours\n",
            "Epoch: 173/14999 | Loss: 0.0012 | Episodes: 36 | Win count: 168 | Win rate: 1.000 | time: 4.56 hours\n",
            "Epoch: 174/14999 | Loss: 0.0027 | Episodes: 20 | Win count: 169 | Win rate: 1.000 | time: 4.57 hours\n",
            "Epoch: 175/14999 | Loss: 0.0011 | Episodes: 16 | Win count: 170 | Win rate: 1.000 | time: 4.58 hours\n",
            "Epoch: 176/14999 | Loss: 0.0007 | Episodes: 21 | Win count: 171 | Win rate: 1.000 | time: 4.60 hours\n",
            "Epoch: 177/14999 | Loss: 0.0007 | Episodes: 35 | Win count: 172 | Win rate: 1.000 | time: 4.62 hours\n",
            "Epoch: 178/14999 | Loss: 0.0009 | Episodes: 42 | Win count: 173 | Win rate: 1.000 | time: 4.65 hours\n",
            "Epoch: 179/14999 | Loss: 0.0009 | Episodes: 51 | Win count: 174 | Win rate: 1.000 | time: 4.68 hours\n",
            "Epoch: 180/14999 | Loss: 0.0011 | Episodes: 36 | Win count: 175 | Win rate: 1.000 | time: 4.70 hours\n",
            "Epoch: 181/14999 | Loss: 0.0005 | Episodes: 78 | Win count: 176 | Win rate: 1.000 | time: 4.75 hours\n",
            "Epoch: 182/14999 | Loss: 0.0016 | Episodes: 63 | Win count: 177 | Win rate: 1.000 | time: 4.79 hours\n",
            "Epoch: 183/14999 | Loss: 0.0005 | Episodes: 3 | Win count: 178 | Win rate: 1.000 | time: 4.80 hours\n",
            "Epoch: 184/14999 | Loss: 0.0006 | Episodes: 2 | Win count: 179 | Win rate: 1.000 | time: 4.80 hours\n",
            "Epoch: 185/14999 | Loss: 0.0025 | Episodes: 13 | Win count: 180 | Win rate: 1.000 | time: 4.81 hours\n",
            "Epoch: 186/14999 | Loss: 0.0007 | Episodes: 16 | Win count: 181 | Win rate: 1.000 | time: 4.82 hours\n",
            "Epoch: 187/14999 | Loss: 0.0010 | Episodes: 39 | Win count: 182 | Win rate: 1.000 | time: 4.84 hours\n",
            "Epoch: 188/14999 | Loss: 0.0012 | Episodes: 34 | Win count: 183 | Win rate: 1.000 | time: 4.87 hours\n",
            "Epoch: 189/14999 | Loss: 0.0006 | Episodes: 42 | Win count: 184 | Win rate: 1.000 | time: 4.91 hours\n",
            "Epoch: 190/14999 | Loss: 0.0013 | Episodes: 28 | Win count: 185 | Win rate: 1.000 | time: 4.93 hours\n",
            "Epoch: 191/14999 | Loss: 0.0003 | Episodes: 20 | Win count: 186 | Win rate: 1.000 | time: 4.94 hours\n",
            "Epoch: 192/14999 | Loss: 0.0007 | Episodes: 9 | Win count: 187 | Win rate: 1.000 | time: 4.95 hours\n",
            "Epoch: 193/14999 | Loss: 0.0038 | Episodes: 64 | Win count: 188 | Win rate: 1.000 | time: 4.99 hours\n",
            "Epoch: 194/14999 | Loss: 0.0015 | Episodes: 74 | Win count: 189 | Win rate: 1.000 | time: 5.04 hours\n",
            "Epoch: 195/14999 | Loss: 0.0018 | Episodes: 60 | Win count: 190 | Win rate: 1.000 | time: 5.08 hours\n",
            "Epoch: 196/14999 | Loss: 0.0013 | Episodes: 7 | Win count: 191 | Win rate: 1.000 | time: 5.08 hours\n",
            "Epoch: 197/14999 | Loss: 0.0006 | Episodes: 41 | Win count: 192 | Win rate: 1.000 | time: 5.11 hours\n",
            "Reached 100% win rate at epoch: 197\n",
            "files: model.h5, model.json\n",
            "n_epoch: 197, max_mem: 800, data: 32, time: 5.13 hours\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18457.776264"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj3EC2GBDkYu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "11b1ae10-58cb-433b-8107-382e01b196dc"
      },
      "source": [
        "rat_cell = random.choice(qmaze.free_cells)\n",
        "qmaze.reset(rat_cell)\n",
        "envstate = qmaze.observe()\n",
        "game_status = 'lose'\n",
        "q_ = []\n",
        "while(game_status != 'win'):\n",
        "  q = model.predict(envstate)\n",
        "  q_.append(q)\n",
        "  action = np.argmax(q[0])\n",
        "  # action = np.argmax(model.predict(envstate))\n",
        "  envstate, reward, game_status = qmaze.act(action)\n",
        "  show(qmaze)\n",
        "  display.clear_output(wait=True)\n",
        "  display.display(pl.gcf())\n",
        "  plt.gca().clear()\n",
        "  sleep(0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAHI0lEQVR4nO3dMU7V6R7H4d+5ZzohJCckREOClSzguADo3IBxB+MCoJtY2h1qIyugYA+cBUBhYqGNEUNMjAQLD4kN+U9xL7lmgiLe9y98r8+TUOF886rzGaD5zaDrugJuvn9d9wOAHyNWCCFWCCFWCCFWCCFWCPHHVX7x4uJid/fu3aYPOD09rVevXjXdrKq6fft23blzp/nu6elp3bp1K2I36a1pu3299e3bt3V8fDy48JNd1/3wx3g87lrb29vrqqr5x2Qyaf7W8/em7Ca9NW23r7f+p7EL+/NtMIQQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4S4EbF+6+bM//IxHo+v+7d1IwwGg+YfBwcH1/3b+i0Nukv+x1SDweDPqvqzqmppaWm8s7PT9AGz2azm5uaabtr97+br16+bblZVLS8v19LSUvPdtD/bPt66ublZ+/v7N/e6YR/suhzZ567rhsA3iRVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCOJj2f7zrYFp/uw6m2W2+WQ6mOZgG/FpihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRB/XOUXHxwc1GBw8S2nnzWZTGp9fb3p5vnu2tpa892Dg4Pe3tt6dzKZVHfJQbyfMZ1Om/97UNXf39nx8XFtb2833RyNRs03q6o+fvz4zc9d6brhwsLC+MmTJ00ft7y8XEdHR003z3f7uMD34cOH3t7berfPK4RJVxM/ffpUZ2dnTTeHw2HzzaqqjY2NOjw8vPC/hJd+Ze26bruqtquqBoNBt7m52fRxk8mkWm+e7z569Kj57tbWVm/v7ePPto8/g+l0GvV3tru7WycnJ003R6NR883L+JkVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQlzpuuF4PK79/f2mD5hOp1EX+Pb29np579bWVvPNRH1dTezjvtX8/HzTzctc6brh0tLSeGdnp+kDZrNZzc3NNd083+3jAt/q6mov7+3jamLidcOky5HD4bDpZlXD64b379/vWt91nU6nvdyK7esC397eXi/v7eNqYuJ1w5Td6/jK6mdWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWfkrXdc0/xuNxzO54PP7lf+auG16R64b9/p2l7M5ms/ry5UvTzSrXDZty3bDfv7OU3el0Wu/fv2+6eRnfBkMIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUKIG3EwrY/DU8PhsM7Ozn7r3aS3pu329dYbfzCtj8NTo9GoTk5OfuvdpLem7fb11u/xbTCEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEECuEuPRg2tfXDRcXF2t3d7fpA4bDYY1Go6ab57v37t1rvjubzWJ2+3zr58+fm+8uLCzE7Pb11nfv3n3zc1e6briystKlXIkbjUbV+hJj1b+vMabs9vnWzc3N5ruTySRmt6+3fo9vgyGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCGEWCHEpTeYfoXHjx8335xMJjUYDHrZXV9fj9jt863Pnz9vvjsajWJ2+3rr06dPv/m5Qdd13/2H/3HdcPzs2bOmjxsOh/XmzZumm1VVy8vLdXR09Fvv9vnW4XDYfHc4HNbZ2VnEbl9v3djYqMPDwwu/ytyI64YpF+3Sdvt86/z8fPPdPi9dplzl/B4/s0IIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUIIsUKISw+mfW1lZaX766+/mj4g6e5O2m7SW893Hz582Hx3b2+v1tbWmm5Op9NaXV1tullV9eDBg3rx4sXPHUz7x3XDGo1GTR83HA6bb9rtb7Pv3clk0nx3NpvVdDptvvny5cumm5e5EdcN0/7rn7Kb9Nbz3T6uMSZ9Zf0eP7NCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCiEuvG359MK2qVqvqdeM3LFbVceNNu/1t2u1vs6pqteu6+Ys+caVTpH0YDAb7Xdfdt9t+N+mtabvX8VbfBkMIsUKImxDrtt3edpPemrb7y9967T+zAj/mJnxlBX6AWCGEWCGEWCGEWCHE30Kj32NNnGReAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDTdOcSwEhbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6329f7-4ffe-43bb-c8e4-03256076f75f"
      },
      "source": [
        "## Q Valor 1º caso\n",
        "# q = [Left, Up, Right, Down]\n",
        "for i in range(27): \n",
        "  print(i, q_[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [[-0.7210754  -0.80778325 -0.4606058  -0.64292574]]\n",
            "1 [[-0.6399625  -0.64251655 -0.612903   -0.47658902]]\n",
            "2 [[-0.5739559  -0.6751237  -0.5406262  -0.47836065]]\n",
            "3 [[-0.6248204  -0.8111185  -0.54526836 -0.4469868 ]]\n",
            "4 [[-0.39121968 -0.5582302  -0.6415194  -0.5142897 ]]\n",
            "5 [[-0.35015258 -0.5647451  -0.60150445 -0.503536  ]]\n",
            "6 [[-0.2980764  -0.51081944 -0.5928156  -0.51673174]]\n",
            "7 [[-0.24438709 -0.34449124 -0.60435605 -0.44761604]]\n",
            "8 [[-0.22144523 -0.44195163 -0.58123994 -0.43934608]]\n",
            "9 [[-0.19712985 -0.50648147 -0.46291816 -0.46536905]]\n",
            "10 [[-0.16997248 -0.44549933 -0.4001455  -0.34300828]]\n",
            "11 [[-0.11991539 -0.45811802 -0.4451522  -0.30331016]]\n",
            "12 [[-0.25352395 -0.5330037  -0.38573793 -0.10717127]]\n",
            "13 [[-0.03298514 -0.4422136  -0.43925485 -0.42576414]]\n",
            "14 [[-0.3755492  -0.43771982 -0.37330407  0.01257284]]\n",
            "15 [[-0.31873536 -0.3471551  -0.51051104  0.03840709]]\n",
            "16 [[-0.16221797 -0.416921    0.05818563 -0.2341844 ]]\n",
            "17 [[-0.12253308 -0.46226865  0.21979623 -0.08525123]]\n",
            "18 [[-0.1069362  -0.4285128   0.31996232 -0.08339983]]\n",
            "19 [[-0.08082254 -0.4082353   0.37337276  0.06081577]]\n",
            "20 [[-0.00867681 -0.33881134  0.4882384   0.1555068 ]]\n",
            "21 [[ 0.1263624  -0.18676336  0.5909112   0.27192402]]\n",
            "22 [[-0.24494557  0.7070591  -0.5259228  -0.35023922]]\n",
            "23 [[ 0.26960808 -0.16039927  0.79036987  0.36044234]]\n",
            "24 [[ 0.2936318  -0.22294153  0.8993806   0.441545  ]]\n",
            "25 [[0.65314084 0.08434804 0.95830774 0.8411644 ]]\n",
            "26 [[ 0.6206517  -0.14138748 -0.2600447   0.97317773]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJm8XEvJA0eZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "c0420163-ffb6-4d19-ac46-4771a2d8ecb6"
      },
      "source": [
        "rat_cell = random.choice(qmaze.free_cells)\n",
        "qmaze.reset(rat_cell)\n",
        "envstate = qmaze.observe()\n",
        "game_status = 'lose'\n",
        "q_ = []\n",
        "while(game_status != 'win'):\n",
        "  q = model.predict(envstate)\n",
        "  q_.append(q)\n",
        "  action = np.argmax(q[0])\n",
        "  # action = np.argmax(model.predict(envstate))\n",
        "  envstate, reward, game_status = qmaze.act(action)\n",
        "  show(qmaze)\n",
        "  display.clear_output(wait=True)\n",
        "  display.display(pl.gcf())\n",
        "  plt.gca().clear()\n",
        "  sleep(0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMbElEQVR4nO3bcYikd33H8ffHXFNpGrWYFeTuNJFeGq+2kHRJU4SaYlouKdz9YZE7CG1KyKE1UlAKKZZU4l9WakG41l6pRAWNp3+UBU8CtZGAeDEbEmPuQmQ9bXNRmjOm/iMaQ7/9YybtZL+7mSd3szO39f2ChXme+e3Md4fhfc8881yqCkma9IpFDyDpwmMYJDWGQVJjGCQ1hkFSYxgkNVPDkOQTSZ5O8tgm9yfJx5KsJXk0yTWzH1PSPA05Yrgb2PcS998I7Bn/HAb+4fzHkrRIU8NQVfcDP3yJJQeAT9XICeA1SV4/qwElzd+OGTzGTuDJie0z433fX78wyWFGRxVccsklv3XVVVfN4Oklbeahhx76QVUtvdzfm0UYBquqo8BRgOXl5VpdXZ3n00s/d5L8+7n83iy+lXgK2D2xvWu8T9I2NYswrAB/PP524jrgR1XVPkZI2j6mfpRI8lngeuCyJGeAvwZ+AaCqPg4cB24C1oAfA3+6VcNKmo+pYaiqQ1PuL+A9M5tI0sJ55aOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6RmUBiS7EvyRJK1JHdscP8bktyX5OEkjya5afajSpqXqWFIchFwBLgR2AscSrJ33bK/Ao5V1dXAQeDvZz2opPkZcsRwLbBWVaer6jngHuDAujUFvGp8+9XA92Y3oqR5GxKGncCTE9tnxvsmfRC4OckZ4Djw3o0eKMnhJKtJVs+ePXsO40qah1mdfDwE3F1Vu4CbgE8naY9dVUerarmqlpeWlmb01JJmbUgYngJ2T2zvGu+bdCtwDKCqvga8ErhsFgNKmr8hYXgQ2JPkiiQXMzq5uLJuzX8AbwdI8mZGYfCzgrRNTQ1DVT0P3A7cCzzO6NuHk0nuSrJ/vOz9wG1JvgF8Frilqmqrhpa0tXYMWVRVxxmdVJzcd+fE7VPAW2c7mqRF8cpHSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUDApDkn1JnkiyluSOTda8M8mpJCeTfGa2Y0qapx3TFiS5CDgC/D5wBngwyUpVnZpYswf4S+CtVfVsktdt1cCStt6QI4ZrgbWqOl1VzwH3AAfWrbkNOFJVzwJU1dOzHVPSPA0Jw07gyYntM+N9k64Erkzy1SQnkuzb6IGSHE6ymmT17Nmz5zaxpC03q5OPO4A9wPXAIeCfkrxm/aKqOlpVy1W1vLS0NKOnljRrQ8LwFLB7YnvXeN+kM8BKVf2sqr4DfItRKCRtQ0PC8CCwJ8kVSS4GDgIr69b8C6OjBZJcxuijxekZzilpjqaGoaqeB24H7gUeB45V1ckkdyXZP152L/BMklPAfcBfVNUzWzW0pK2VqlrIEy8vL9fq6upCnlv6eZHkoapafrm/55WPkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySmkFhSLIvyRNJ1pLc8RLr3pGkkizPbkRJ8zY1DEkuAo4ANwJ7gUNJ9m6w7lLgz4EHZj2kpPkacsRwLbBWVaer6jngHuDABus+BHwY+MkM55O0AEPCsBN4cmL7zHjf/0pyDbC7qr74Ug+U5HCS1SSrZ8+efdnDSpqP8z75mOQVwEeB909bW1VHq2q5qpaXlpbO96klbZEhYXgK2D2xvWu87wWXAm8BvpLku8B1wIonIKXta0gYHgT2JLkiycXAQWDlhTur6kdVdVlVXV5VlwMngP1VtbolE0vaclPDUFXPA7cD9wKPA8eq6mSSu5Ls3+oBJc3fjiGLquo4cHzdvjs3WXv9+Y8laZG88lFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWDwpBkX5InkqwluWOD+9+X5FSSR5N8OckbZz+qpHmZGoYkFwFHgBuBvcChJHvXLXsYWK6q3wS+APzNrAeVND9DjhiuBdaq6nRVPQfcAxyYXFBV91XVj8ebJ4Bdsx1T0jwNCcNO4MmJ7TPjfZu5FfjSRnckOZxkNcnq2bNnh08paa5mevIxyc3AMvCRje6vqqNVtVxVy0tLS7N8akkztGPAmqeA3RPbu8b7XiTJDcAHgLdV1U9nM56kRRhyxPAgsCfJFUkuBg4CK5MLklwN/COwv6qenv2YkuZpahiq6nngduBe4HHgWFWdTHJXkv3jZR8Bfhn4fJJHkqxs8nCStoEhHyWoquPA8XX77py4fcOM55K0QF75KKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqRkUhiT7kjyRZC3JHRvc/4tJPje+/4Ekl896UEnzMzUMSS4CjgA3AnuBQ0n2rlt2K/BsVf0q8HfAh2c9qKT5GXLEcC2wVlWnq+o54B7gwLo1B4BPjm9/AXh7ksxuTEnztGPAmp3AkxPbZ4Df3mxNVT2f5EfAa4EfTC5Kchg4PN78aZLHzmXoBbmMdX/PBWw7zQrba97tNCvAr53LLw0Jw8xU1VHgKECS1apanufzn4/tNO92mhW217zbaVYYzXsuvzfko8RTwO6J7V3jfRuuSbIDeDXwzLkMJGnxhoThQWBPkiuSXAwcBFbWrVkB/mR8+4+Af6uqmt2YkuZp6keJ8TmD24F7gYuAT1TVySR3AatVtQL8M/DpJGvADxnFY5qj5zH3ImynebfTrLC95t1Os8I5zhv/YZe0nlc+SmoMg6Rmy8OwnS6nHjDr+5KcSvJoki8neeMi5pyY5yXnnVj3jiSVZGFfsw2ZNck7x6/vySSfmfeM62aZ9l54Q5L7kjw8fj/ctIg5x7N8IsnTm10XlJGPjf+WR5NcM/VBq2rLfhidrPw28CbgYuAbwN51a/4M+Pj49kHgc1s503nO+nvAL41vv3tRsw6dd7zuUuB+4ASwfKHOCuwBHgZ+Zbz9ugv5tWV0Uu/d49t7ge8ucN7fBa4BHtvk/puALwEBrgMemPaYW33EsJ0up546a1XdV1U/Hm+eYHRNx6IMeW0BPsTo/678ZJ7DrTNk1tuAI1X1LEBVPT3nGScNmbeAV41vvxr43hzne/EgVfcz+jZwMweAT9XICeA1SV7/Uo+51WHY6HLqnZutqarngRcup563IbNOupVRhRdl6rzjQ8bdVfXFeQ62gSGv7ZXAlUm+muREkn1zm64bMu8HgZuTnAGOA++dz2jn5OW+t+d7SfT/F0luBpaBty16ls0keQXwUeCWBY8y1A5GHyeuZ3Qkdn+S36iq/1roVJs7BNxdVX+b5HcYXcfzlqr670UPNgtbfcSwnS6nHjIrSW4APgDsr6qfzmm2jUyb91LgLcBXknyX0WfLlQWdgBzy2p4BVqrqZ1X1HeBbjEKxCEPmvRU4BlBVXwNeyeg/WF2IBr23X2SLT4rsAE4DV/B/J3F+fd2a9/Dik4/HFnQCZ8isVzM6KbVnETO+3HnXrf8Kizv5OOS13Qd8cnz7MkaHvq+9gOf9EnDL+PabGZ1jyALfD5ez+cnHP+TFJx+/PvXx5jDwTYzq/23gA+N9dzH6FxdGpf08sAZ8HXjTAl/cabP+K/CfwCPjn5VFzTpk3nVrFxaGga9tGH30OQV8Ezh4Ib+2jL6J+Oo4Go8Af7DAWT8LfB/4GaMjr1uBdwHvmnhtj4z/lm8OeR94SbSkxisfJTWGQVJjGCQ1hkFSYxgkNYZBUmMYJDX/AwqkUdV2nfELAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13fejZ2HKmA5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98cc937e-ff41-4ce3-b982-a2e4a6360cdf"
      },
      "source": [
        "## Q Valor 2º caso\n",
        "# q = [Left, Up, Right, Down]\n",
        "for i in range(19): \n",
        "  print(i,q_[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [[-0.22144523 -0.44195163 -0.58123994 -0.43934608]]\n",
            "1 [[-0.19712985 -0.50648147 -0.46291816 -0.46536905]]\n",
            "2 [[-0.16997248 -0.44549933 -0.4001455  -0.34300828]]\n",
            "3 [[-0.11991539 -0.45811802 -0.4451522  -0.30331016]]\n",
            "4 [[-0.25352395 -0.5330037  -0.38573793 -0.10717127]]\n",
            "5 [[-0.03298514 -0.4422136  -0.43925485 -0.42576414]]\n",
            "6 [[-0.3755492  -0.43771982 -0.37330407  0.01257284]]\n",
            "7 [[-0.31873536 -0.3471551  -0.51051104  0.03840709]]\n",
            "8 [[-0.16221797 -0.416921    0.05818563 -0.2341844 ]]\n",
            "9 [[-0.12253308 -0.46226865  0.21979623 -0.08525123]]\n",
            "10 [[-0.1069362  -0.4285128   0.31996232 -0.08339983]]\n",
            "11 [[-0.08082254 -0.4082353   0.37337276  0.06081577]]\n",
            "12 [[-0.00867681 -0.33881134  0.4882384   0.1555068 ]]\n",
            "13 [[ 0.1263624  -0.18676336  0.5909112   0.27192402]]\n",
            "14 [[-0.24494557  0.7070591  -0.5259228  -0.35023922]]\n",
            "15 [[ 0.26960808 -0.16039927  0.79036987  0.36044234]]\n",
            "16 [[ 0.2936318  -0.22294153  0.8993806   0.441545  ]]\n",
            "17 [[0.65314084 0.08434804 0.95830774 0.8411644 ]]\n",
            "18 [[ 0.6206517  -0.14138748 -0.2600447   0.97317773]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}