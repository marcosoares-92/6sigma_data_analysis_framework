{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_1"
    ]
   },
   "outputs": [],
   "source": [
    "## Análise de distribuição estatística dos dados - Histograma, normalidade e transformação Box-Cox\n",
    "\n",
    "## CÉLULA 1: Instruções de carregamento do arquivo e bibliotecas a ser importadas\n",
    "\n",
    "\"\"\"\"\n",
    "    Para executar uma CÉLULA, pressione o botão \"Run\" no topo, com a CÉLULA selecionada, ou pressione:\n",
    "    \n",
    "    Shift + Enter\n",
    "\n",
    "-Se seus dados estiverem em um arquivo xlsx utilize a CÉLULA 2\n",
    "\n",
    "-Se seus dados estiverem em um arquivo csv contendo cabeçalhos, utilize a CÉLULA 3\n",
    "\n",
    "-Se seus dados estiverem em um arquivo csv sem cabeçalhos, utilize a CÉLULA 4\n",
    "\n",
    "-Utilize apenas a CÉLULA correta\n",
    "-Substitua o texto entre aspas na variável \"caminho\" pelo endereço do arquivo em sua máquina.\n",
    "\n",
    "EXECUTE ESTA CÉLULA ANTES DE PROSSEGUIR\n",
    "\n",
    "EXECUTE APENAS UMA CÉLULA POR VEZ\n",
    "\n",
    "-Caso deseje apagar a saída de uma célula carregada, mas não deseje carregar uma nova saída, vá à aba superior, escolha o ícone\n",
    "do teclado (open the command palette/ jupyter-notebook command group) e selecione clear cell output.\n",
    "\n",
    "@author: Marco César Prado Soares, MSc.\n",
    "Especialista Lean Six Sigma Master Black Belt, Eng. Químico, MSc. Eng. Mecatrônica (instrumentação) \n",
    "Marco.Soares@br.ey.com; marcosoares.feq@gmail.com\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_2"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 2: dados em arquivo xlsx\n",
    "\n",
    "caminho = \"D:\\Drive\\FM2S\\EAD\\Green Belt em Python\\Machine Learning - módulo 2 - ANN regression\\ANN.1 - Apartment price analysis\\prices_apartments.xlsx\"\n",
    "dataset = pd.read_excel(caminho)\n",
    "\n",
    "dataset\n",
    "#SIGA PARA A CÉLULA 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_3"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 3: dados em arquivo csv com cabeçalho\n",
    "\n",
    "caminho = \"D:\\Drive\\FM2S\\EAD\\Green Belt em Python\\Machine Learning - módulo 3 - ANN classification\\ANN.Class - 2 - advertising campaign\\delivery_app_data.csv\"\n",
    "dataset = pd.read_csv(caminho)\n",
    "\n",
    "dataset\n",
    "#SIGA PARA A CÉLULA 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_4"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 4: dados em arquivo csv sem cabeçalho\n",
    "\n",
    "caminho = \"D:\\Drive\\FM2S\\EAD\\Green Belt em Python\\Machine Learning - módulo 2 - ANN regression\\ANN.4 - Boston housing price\\housing_boston_data.txt\"\n",
    "dataset = pd.read_csv(caminho, delim_whitespace=True, header=None)\n",
    "\n",
    "#here, the dataset is in a textfile. In these cases, use delim_withespace = True\n",
    "#or df = pd.read_fwf('output_list.txt')\n",
    "#since data has no Head, keep header = None\n",
    "#if there is Head, eliminate ‘header’ from the arguments of the function\n",
    "\n",
    "dataset\n",
    "#SIGA PARA A CÉLULA 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_5"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 5: Eliminar linhas com entradas nulas\n",
    "\n",
    "\"\"\"\n",
    "-Utilize este CÉLULA apenas se desejar limpar as entradas nulas da sua base de dados\n",
    "\n",
    "-Esta CÉLULA eliminará todas as linhas contendo entradas nulas. Caso NÃO DESEJE ISTO, vá direto à CÉLULA 6, sem executar esta\n",
    "célula.\n",
    "\"\"\"\n",
    "\n",
    "dataset = dataset.dropna(axis=0)\n",
    "dataset\n",
    "#SIGA PARA A CÉLULA 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "CELL_6"
    ]
   },
   "source": [
    "# CÉLULA 6: Instruções Gerais\n",
    "\n",
    "### ATENÇÃO: NÃO EXECUTE ESTA CÉLULA - Ela contém apenas texto explicativo\n",
    "\n",
    "Este notebook destina-se à análise de distribuição estatística dos dados, e transformação deles em dados que sigam a distribuição normal. À seguir, são dadas as análises disponíveis. Siga à célula correspondente à análise desejada:\n",
    "\n",
    "## 1) Histograma com ou sem curva normal ajustada\n",
    "\n",
    "- Aqui será construído o histograma dos dados.\n",
    "- Este sistema permite a verificação simultânea da curva normal ajustada.\n",
    "- O resultado pode ser prejudicado para dados com diferenças extremamente pequenas. Neste caso, pode ser mais interessante utilizar o comando de histograma do R (exemplo: hist(y,main=\"Histograma do valor de inventario\", xlab = \"Valor\", ylab = \"Contagem\", col=\"red\"), o qual já é otimizado para esta situação particular.\n",
    "- Também são retornados: \n",
    "    1) um resumo das estatísticas gerais dos dados: total de dados avaliados; média; desvio-padrão; valor mais elevado; valor \n",
    "        mais baixo; e bin size, a largura da barra do histograma.\n",
    "    2) a tabela de frequencias usada na construção do histograma\n",
    "\n",
    "Siga para as CÉLULAS 7 a 9.\n",
    "----------------------------------------\n",
    "\n",
    "_______________________________________________________________________________________________________________________________\n",
    "_______________________________________________________________________________________________________________________________\n",
    "_______________________________________________________________________________________________________________________________\n",
    "\n",
    "## 2) Testes de normalidade\n",
    "\n",
    "- Aqui será avaliado se os dados podem ser descritos por uma distribuição estatística do tipo normal, por meio de dois testes distintos: teste de Lilliefors e teste de Anderson-Darling.\n",
    "- Note que existem outros testes (em especial testes Anderson-Darling) destinados à avaliação de outras distribuições. O pacote nortest do R fornece uma gama de testes deste tipo, em variedade maior que o disponibilizado no pacote statsmodels do Python.\n",
    "- Este sistema retornará dois dataframes contendo p-valores, a probabilidade de uma hipótese-nula ser verdadeira. Neste caso, a hipótese-nula dos testes de hipótese (Lilliefors e Anderson-Darling) é que os dados seguem a normal.\n",
    "\n",
    "Siga para as CÉLULAS 10 a 12.\n",
    "----------------------------------------\n",
    "\n",
    "_______________________________________________________________________________________________________________________________\n",
    "_______________________________________________________________________________________________________________________________\n",
    "_______________________________________________________________________________________________________________________________\n",
    "\n",
    "## 3) Transformação Box-Cox\n",
    "\n",
    "- Este sistema transforma o conjunto de dados original em dados descritos pela curva normal.\n",
    "- Também os limites de especificação transformados.\n",
    "- Possibilita, assim, que seja analisado se os dados estão dentro das especificações.\n",
    "\n",
    "Siga para as CÉLULAS 13 a 15.\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_7"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 7: Função de construção do histograma dos dados\n",
    "\n",
    "#Execute esta CÉLULA para carregar a função\n",
    "\n",
    "def histogram(y, largura_da_barra, normal_curve_overlay = True, legenda_dos_dados = None, titulo_y = None, titulo_histograma = None):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import matplotlib\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    #Calculo do bin size - largura do histograma:\n",
    "    #1: Encontrar o menor (lowest) e o maior (highest) valor dentro da tabela de dados)\n",
    "    #2: Calcular rangehist = highest - lowest\n",
    "    #3: Calcular quantidade de dados (samplesize) de entrada fornecidos\n",
    "    #4: Calcular a quantidade de celulas da tabela de frequencias (ncells)\n",
    "    #ncells = numero inteiro mais proximo da (raiz quadrada de samplesize)\n",
    "    #5: Calcular binsize = rangehist/(ncells)\n",
    "    #ATENCAO: Nao se esquecer de converter range, ncells, samplesize e binsize para valores absolutos (modulos)\n",
    "    #isso porque a largura do histograma tem que ser um numero positivo\n",
    "\n",
    "    y = y.reset_index(drop=True)\n",
    "    #faz com que os indices desta serie sejam consecutivos e a partir de zero\n",
    "\n",
    "    #Estatisticas gerais: media (mu) e desvio-padrao (sigma)\n",
    "    mu = y.mean() \n",
    "    sigma = y.std() \n",
    "\n",
    "    #Calculo do bin-size\n",
    "    highest = y.max()\n",
    "    lowest = y.min()\n",
    "    rangehist = highest - lowest\n",
    "    rangehist = abs(rangehist)\n",
    "    #garante que sera um numero positivo\n",
    "    samplesize = y.count() #contagem do total de entradas\n",
    "    ncells = (samplesize)**0.5 #potenciacao: ** - raiz quadrada de samplesize\n",
    "    #resultado da raiz quadrada e sempre positivo\n",
    "    ncells = round(ncells) #numero \"redondo\" mais proximo\n",
    "    ncells = int(ncells) #parte inteira do numero arredondado\n",
    "    #ncells = numero de linhas da tabela de frequencias\n",
    "    binsize = rangehist/ncells\n",
    "    binsize = round(binsize)\n",
    "    binsize = int(binsize) #precisa ser inteiro\n",
    "    \n",
    "    #Construcao da tabela de frequencias\n",
    "\n",
    "    j = 0 #indice da tabela de frequencias\n",
    "    #Este indice e diferente do ordenamento dos valores em ordem crescente\n",
    "    xhist = []\n",
    "    #Lista vazia que contera os x do histograma\n",
    "    yhist = []\n",
    "    #Listas vazia que conteras o y do histograma\n",
    "    hist_labels = []\n",
    "    #Esta lista gravara os limites da barra na forma de strings\n",
    "\n",
    "    pontomediodabarra = lowest + binsize/2 \n",
    "    limitedabarra = lowest + binsize\n",
    "    #ponto medio da barra \n",
    "    #limite da primeira barra do histograma\n",
    "    seriedohist1 = y\n",
    "    seriedohist1 = seriedohist1.sort_values(ascending=True)\n",
    "    #serie com os valores em ordem crescente\n",
    "    seriedohist1 = seriedohist1.reset_index(drop=True)\n",
    "    #garante que a nova serie tenha indices consecutivos, iniciando em zero\n",
    "    i = 0 #linha inicial da serie do histograma em ordem crescente\n",
    "    valcomparado = seriedohist1[i]\n",
    "    #primeiro valor da serie, o mais baixo\n",
    "\n",
    "    while (j <= (ncells-1)):\n",
    "        \n",
    "        #para quando termina o numero de linhas da tabela\n",
    "        xhist.append(pontomediodabarra)\n",
    "        #tempo da tabela de frequencias\n",
    "        cont = 0\n",
    "        #variavel de contagem do histograma\n",
    "        #contagem deve ser reiniciada\n",
    "       \n",
    "        if (i < samplesize):\n",
    "            #2 condicionais para impedir que um termo de indice inexistente\n",
    "            #seja acessado\n",
    "            while (valcomparado <= limitedabarra) and (valcomparado < highest):\n",
    "                #o segundo criterio garante a parada em casos em que os dados sao\n",
    "                #muito proximos\n",
    "                    cont = cont + 1 #adiciona contagem a tabela de frequencias\n",
    "                    i = i + 1\n",
    "                    \n",
    "                    if (i < samplesize): \n",
    "                        valcomparado = seriedohist1[i]\n",
    "        \n",
    "        yhist.append(cont) #valor de ocorrencias contadas\n",
    "        \n",
    "        limite_infdabarra = pontomediodabarra - binsize/2\n",
    "        rotulo = \"%.2f - %.2f\" %(limite_infdabarra, limitedabarra)\n",
    "        #intervalo da tabela de frequencias\n",
    "        #%.2f: 2 casas decimais de aproximação\n",
    "        hist_labels.append(rotulo)\n",
    "        \n",
    "        pontomediodabarra = pontomediodabarra + binsize\n",
    "        #tanto os pontos medios quanto os limites se deslocam do mesmo intervalo\n",
    "        \n",
    "        limitedabarra = limitedabarra + binsize\n",
    "        #proxima barra\n",
    "        \n",
    "        j = j + 1\n",
    "    \n",
    "    #Temos que verificar se o valor maximo foi incluido\n",
    "    #isso porque o processo de aproximacao por numero inteiro pode ter\n",
    "    #arredondado para baixo e excluido o limite superior\n",
    "    #Porem, note que na ultima iteracao o limite superior da barra foi \n",
    "    #somado de binsize, mas como j ja e maior que ncells-1, o loop parou\n",
    "    \n",
    "    #assim, o limitedabarra nesse momento e o limite da barra que seria\n",
    "    #construida em seguida, nao da ultima barra da tabela de frequencias\n",
    "    #isso pode fazer com que esta barra ja seja maior que o highest\n",
    "    \n",
    "    #note porem que nao aumentamos o valor do limite inferior da barra\n",
    "    #por isso, basta vermos se ele mais o binsize sao menores que o valor mais alto\n",
    "    \n",
    "    \n",
    "    while ((limite_infdabarra+binsize) < highest):\n",
    "        \n",
    "        #vamos criar novas linhas ate que o ponto mais alto do histograma\n",
    "        #tenha sido contado\n",
    "        ncells = ncells + 1 #adiciona uma linha a tabela de frequencias\n",
    "        xhist.append(pontomediodabarra)\n",
    "        \n",
    "        cont = 0 #variavel de contagem do histograma\n",
    "        \n",
    "        while (valcomparado <= limitedabarra):\n",
    "                cont = cont + 1 #adiciona contagem a tabela de frequencias\n",
    "                i = i + 1\n",
    "                if (i < samplesize):\n",
    "                    valcomparado = seriedohist1[i]\n",
    "                    #apenas se i ainda nao e maior que o total de dados\n",
    "                \n",
    "                else: \n",
    "                    \n",
    "                    break\n",
    "        \n",
    "        #parar o loop se i atingiu um tamanho maior que a quantidade \n",
    "        #de dados.Temos que ter este cuidado porque estamos acrescentando\n",
    "        #mais linhas a tabela de frequencias para corrigir a aproximacao\n",
    "        #de ncells por um numero inteiro\n",
    "        \n",
    "        yhist.append(cont) #valor de ocorrencias contadas\n",
    "        \n",
    "        limite_infdabarra = pontomediodabarra - binsize/2\n",
    "        rotulo = \"%.2f - %.2f\" %(limite_infdabarra, limitedabarra)\n",
    "        #intervalo da tabela de frequencias - 2 casas decimais\n",
    "        hist_labels.append(rotulo)\n",
    "        \n",
    "        pontomediodabarra = pontomediodabarra + binsize\n",
    "        #tanto os pontos medios quanto os limites se deslocam do mesmo intervalo\n",
    "        \n",
    "        limitedabarra = limitedabarra + binsize\n",
    "        #proxima barra\n",
    "        \n",
    "    estatisticas_col1 = []\n",
    "    #contera as descricoes das colunas da tabela de estatisticas gerais\n",
    "    estatisticas_col2 = []\n",
    "    #contera os valores da tabela de estatisticas gerais\n",
    "    \n",
    "    estatisticas_col1.append(\"Total de dados avaliados\")\n",
    "    estatisticas_col2.append(samplesize)\n",
    "    estatisticas_col1.append(\"Média (mu)\")\n",
    "    estatisticas_col2.append(mu)\n",
    "    estatisticas_col1.append(\"Desvio-padrão (sigma)\")\n",
    "    estatisticas_col2.append(sigma)\n",
    "    estatisticas_col1.append(\"Valor mais elevado\")\n",
    "    estatisticas_col2.append(highest)\n",
    "    estatisticas_col1.append(\"Valor mais baixo\")\n",
    "    estatisticas_col2.append(lowest)\n",
    "    estatisticas_col1.append(\"Range dos dados\\n(valor máximo - valor mínimo)\")\n",
    "    estatisticas_col2.append(rangehist)\n",
    "    estatisticas_col1.append(\"Bin size\\n(largura da barra do histograma)\")\n",
    "    estatisticas_col2.append(binsize)\n",
    "    estatisticas_col1.append(\"Quantidade de linhas\\nna tabela de frequências\")\n",
    "    estatisticas_col2.append(ncells)\n",
    "    #como o comando append grava linha a linha em sequencia, garantimos\n",
    "    #a correspondencia das colunas\n",
    "    #Assim como em qualquer string, incluindo de rotulos de graficos\n",
    "    #os \\n sao lidos como quebra de linha\n",
    "    \n",
    "    d1 = {\"Estatísticas gerais dos dados\": estatisticas_col1, \"Valor calculado\": estatisticas_col2}\n",
    "    #dicionario das duas series, para criar o dataframe com as descricoes\n",
    "    estatisticas_gerais = pd.DataFrame(data = d1)\n",
    "    \n",
    "    #Casos os títulos estejam presentes (valor nao e None):\n",
    "    #vamos utiliza-los\n",
    "    #Caso contrario, vamos criar nomenclaturas genericas para o histograma\n",
    "    \n",
    "    eixo_y = \"Counting/Frequency\"\n",
    "    \n",
    "    if not (legenda_dos_dados is None):\n",
    "        xlabel = legenda_dos_dados\n",
    "    \n",
    "    else:\n",
    "        xlabel = \"Frequency\\n table data\"\n",
    "    \n",
    "    if not (titulo_y is None):\n",
    "        eixo_x = titulo_y\n",
    "        #lembre-se que no histograma, os dados originais vao pro eixo X\n",
    "        #O eixo Y vira o eixo da contagem/frequencia daqueles dados\n",
    "    \n",
    "    else:\n",
    "        eixo_x = \"X: Mean value of the interval\"\n",
    "    \n",
    "    if not (titulo_histograma is None):\n",
    "        string1 = \"- $\\mu = %.2f$, $\\sigma = %.2f$\" %(mu, sigma)\n",
    "        main_label = titulo_histograma + string1\n",
    "        #concatena a string do titulo a string com a media e desvio-padrao\n",
    "        #%.2f: o numero entre %. e f indica a quantidade de casas decimais da \n",
    "        #variavel float f. No caso, arredondamos para 2 casas\n",
    "        #NAO SE ESQUECA DO PONTO: ele que indicara que sera arredondado o \n",
    "        #numero de casas\n",
    "    \n",
    "    else:\n",
    "        main_label = \"Data Histogram - $\\mu = %.2f$, $\\sigma = %.2f$\" %(mu, sigma)\n",
    "        #os simbolos $\\ $ substituem o simbolo pela letra grega\n",
    "    \n",
    "    d2 = {\"Intervalos considerados\": hist_labels, eixo_x: xhist, eixo_y: yhist}\n",
    "    #dicionario que compoe a tabela de frequencias\n",
    "    tab_frequencias = pd.DataFrame(data = d2)\n",
    "    #cria a tabela de frequencias como um dataframe de saida\n",
    "    \n",
    "    \"\"\"\n",
    "    Normal curve equation\n",
    "    \n",
    "    y = p(X) = (1/((sigma)*sqrt(2*pi)))*exp((-1)*(X-mu)²/2(sigma²))\n",
    "    0 <= p(X) <= 1\n",
    "    mu = mean value of X\n",
    "    sigma = standard deviation of X\n",
    "    sqrt = square root function\n",
    "    pi = 3.14159...\n",
    "    e = 2.71828...\n",
    "    exp = e** = e^ = exponential function\n",
    "    \n",
    "    numpy functions available:\n",
    "        np.sqrt(X): square root of X\n",
    "        np.pi = value of pi\n",
    "        np.exp(X) = exponential function of X = e**X = e^X = exp(X)\n",
    "    \n",
    "    \"\"\"\n",
    "    #parametros da normal ja calculados:\n",
    "    #mu e sigma\n",
    "    #numero de bins: ncells\n",
    "    #limites de especificacao: lsl,usl - target\n",
    "    \n",
    "    #valor maximo do histograma\n",
    "    max_hist = max(yhist)\n",
    "    #seleciona o valor maximo da serie, para ajustar a curva normal\n",
    "    #isso porque a normal é criada com valores entre 0 e 1\n",
    "    #multiplicando ela por max_hist, fazemos ela se adequar a altura do histograma\n",
    "    \n",
    "    if (normal_curve_overlay == True):\n",
    "        \n",
    "        #construir a normal ajustada/esperada\n",
    "        #vamos criar pontos ao redor da media mu - 4sigma ate mu + 4sigma, \n",
    "        #de modo a garantir a quase totalidade da curva normal. \n",
    "        #O incremento será de 0.10 sigma a cada iteracao\n",
    "        x_inf = mu -(4)*sigma\n",
    "        x_sup = mu + 4*sigma\n",
    "        x_inc = (0.10)*sigma\n",
    "        \n",
    "        x_normal_adj = []\n",
    "        y_normal_adj = []\n",
    "        \n",
    "        x_adj = x_inf\n",
    "        y_adj = ((1 / (np.sqrt(2 * np.pi) * sigma)) *np.exp(-0.5 * (1 / sigma * (x_adj - mu))**2))\n",
    "        x_normal_adj.append(x_adj)\n",
    "        y_normal_adj.append(y_adj)\n",
    "        \n",
    "        while(x_adj < x_sup): \n",
    "            \n",
    "            x_adj = x_adj + x_inc\n",
    "            y_adj = ((1 / (np.sqrt(2 * np.pi) * sigma)) *np.exp(-0.5 * (1 / sigma * (x_adj - mu))**2))\n",
    "            x_normal_adj.append(x_adj)\n",
    "            y_normal_adj.append(y_adj)\n",
    "        \n",
    "        #vamos ajustar a altura da curva ao histograma. Para isso, precisamos\n",
    "        #calcular quantas vezes o ponto mais alto do histograma é maior que o ponto\n",
    "        #mais alto da normal (chamaremos essa relação de fator). A seguir,\n",
    "        #multiplicamos cada elemento da normal por este mesmo fator\n",
    "        max_normal = max(y_normal_adj) \n",
    "        #maximo da normal ajustada, numero entre 0 e 1\n",
    "        \n",
    "        fator = (max_hist)/(max_normal)\n",
    "        size_normal = len(y_normal_adj) #quantidade de dados criados\n",
    "        \n",
    "        i = 0\n",
    "        while (i < size_normal):\n",
    "            y_normal_adj[i] = (y_normal_adj[i])*(fator)\n",
    "            i = i + 1\n",
    "    \n",
    "    #Fazer o grafico\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.bar(xhist, yhist, width = largura_da_barra, label=xlabel, color='blue')\n",
    "    #ajuste manualmente a largura, width, para deixar as barras mais ou menos proximas\n",
    "    \n",
    "    if (normal_curve_overlay == True):\n",
    "    \n",
    "        #adicionar a normal\n",
    "        ax.plot(x_normal_adj, y_normal_adj, color = 'black', label = 'Adjusted/expected\\n normal curve')\n",
    "    \n",
    "    ax.set_xlabel(eixo_x)\n",
    "    ax.set_ylabel(eixo_y)\n",
    "    ax.set_title(main_label)\n",
    "    ax.set_xticks(xhist)\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.grid(True) #mude para False, caso não deseje ver as linhas de grade\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return estatisticas_gerais, tab_frequencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "CELL_8"
    ]
   },
   "source": [
    "# CÉLULA 8: Função para construção do histograma e da tabela de frequência dos dados\n",
    "\n",
    "### ATENÇÃO: NÃO EXECUTE ESTA CÉLULA - Ela contém apenas texto explicativo    \n",
    "    \n",
    "INSTRUÇÕES:\n",
    "\n",
    "1) Esta função retorna 2 dataframes:\n",
    "    \n",
    "    1) dataframe estatisticas_gerais, um resumo das estatísticas gerais dos dados: total de dados avaliados; média; desvio-padrão; valor mais elevado; valor mais baixo; e bin size, a largura da barra do histograma.\n",
    "    \n",
    "    2) dataframe tab_frequencias, que mostra a tabela de frequencias usada na construção do histograma\n",
    "\n",
    "2) Os parâmetros x e y da função devem ser apenas listas, não dataframe(s)\n",
    "\n",
    "3) Esta função retorna 2 dataframes. Deste modo, você precisa chamar 2 daframes, não apenas um.\n",
    "\n",
    "Exemplo: caso deseje salvar o dataframe estatisticas_gerais em df1,  e o dataframe tab_frequencias em df2, e os dados estão na variável y:\n",
    "    \n",
    "       df1, df2 = histogram(y, largura_da_barra = 10, normal_curve_overlay = True, legenda_dos_dados = None, titulo_y = None, titulo_histograma = None)\n",
    "    \n",
    "Note que o primeiro será sempre estatisticas_gerais, e o segundo será tab_frequencias\n",
    "\n",
    "Você pode dar outros nomes para os dataframes chamados:\n",
    "   \n",
    "       estatisticas_gerais, tab_frequencias = histogram(y, largura_da_barra = 10, normal_curve_overlay = True, legenda_dos_dados = None, titulo_y = None, titulo_histograma = None)\n",
    "\n",
    "4) Caso QUEIRA mostrar a curva normal ajustada, mantenha:\n",
    "    \n",
    "        normal_curve_overlay = True\n",
    "\n",
    "CASO NAO QUEIRA MOSTRAR A NORMAL:\n",
    "    \n",
    "        normal_curve_overlay = False\n",
    "\n",
    "5) Altere o valor de largura_da_barra até conseguir ver o histograma de forma clara\n",
    "    \n",
    "6) Os demais parâmetros são textos (strings). Declare-os entre aspas ou mantenha o valor None\n",
    "    \n",
    "##### NOTA: ESTE ALGORITMO PODE FALHAR CASO TODOS OS DADOS SEJAM MUITO PRÓXIMOS. \n",
    "\n",
    "Isso porque a largura ncells teria de ser tão larga que uma única barra englobaria todos os dados. Além disso, principalmente quando se usa a transformação Box-Cox, a diferença entre os dados transformados pode ser baixa demais para que a memória \n",
    "disponível no sistema identifique eles como números efetivamente diferentes (no arredondamento, eles passam a ser considerados iguais, fazendo com que o loop de comparação que verifica se um dado está numa barra ou na seguinte não possa ser finalizado. Isto gera MemoryError).\n",
    "\n",
    "CASO QUEIRA, mesmo assim, CONSTRUIR O HISTOGRAMA, apague as linhas de cálculo do bin size (de binsize = rangehist/ncells até binsize = int(binsize)) e substitua por um valor desejado de binsize. Por exemplo, substitua as linhas por:\n",
    "    \n",
    "    binsize = 10\n",
    "\n",
    "Assim, você definirá manualmente o tamanho da barra, podendo \"esticá-la\" para englobar todos os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_9"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 9: CONSTRUÇÃO DO HISTOGRAMA PARA SEUS DADOS\n",
    "\n",
    "#DEFINA A VARIAVEL y para a qual será construído o histograma. \n",
    "#Basta substituir o valor entre aspas pelo nome da coluna onde está Y:\n",
    "\n",
    "y = dataset['Y']\n",
    "\n",
    "#NOTA: o valor y necessariamente deve ser uma série.\n",
    "\n",
    "estatisticas_gerais, tab_frequencias = histogram(y = y, largura_da_barra = 10, normal_curve_overlay = True, legenda_dos_dados = None, titulo_y = None, titulo_histograma = None)\n",
    "\n",
    "# Altere manualmente o valor numérico da largura_da_barra do histograma até alcançar um espaçamento mínimo entre barras\n",
    "#consecutivas. O valor da largura da barra depende de cada conjunto particular de dados utilizado.\n",
    "\n",
    "\"\"\"\n",
    "Substitua os demais campos None de acordo com as instruções dadas na CÉLULA 8.\n",
    "- Os títulos e legendas devem ser fornecidos como um texto entre aspas.\n",
    "- Modifique normal_curve_overlay = True para normal_curve_overlay = False caso não deseje ver a normal sobreposta.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "estatisticas_gerais\n",
    "tab_frequencias\n",
    "\n",
    "\"\"\"VOCÊ DESEJA EXPORTAR OS DADOS?\n",
    "Caso deseje exportar os dados, copie as seguintes linhas para o espaço não-vermelho após as aspas. Substitua o endereço pela\n",
    "pasta onde você deseja salvar seu arquivo. Substitua estatisticas e tabela_freq pelos nomes que deseja para seus arquivos. \n",
    "Mantenha a extensão csv. Você pode também optar por exportar apenas uma das tabelas (neste caso, copie apenas a desejada).\n",
    "\n",
    "estatisticas_gerais.to_csv(r\"D:\\Drive\\FM2S\\EAD\\Green Belt em Python\\Machine Learning - módulo 3 - ANN classification\\ANN.Class - 1 - user satisfaction\\estatisticas.csv\", index = False)\n",
    "\n",
    "tab_frequencias.to_csv(r\"D:\\Drive\\FM2S\\EAD\\Green Belt em Python\\Machine Learning - módulo 3 - ANN classification\\ANN.Class - 1 - user satisfaction\\tabela_freq.csv\", index = False)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_10"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 10: Função de avaliação da normalidade dos dados(probabilidade de os dados serem representados por uma curva normal)\n",
    "\n",
    "#Execute esta CÉLULA para carregar a função\n",
    "\n",
    "def testes_normalidade(y, alpha = 0.10):\n",
    "    import pandas as pd\n",
    "    from statsmodels.stats import diagnostic\n",
    "    \n",
    "    lista1 = []\n",
    "    #esta lista sera a primeira coluna, com as descrições das demais\n",
    "    lista1.append(\"p-valor: probabilidade de os dados serem descritos pela normal\")\n",
    "    lista1.append(\"Probabilidade de seguir a normal (%)\")\n",
    "    lista1.append(\"alpha\")\n",
    "    lista1.append(\"Critério: não segue a normal se p < alpha = %.3f\" %(alpha))\n",
    "    #%.3f apresenta f com 3 casas decimais\n",
    "    #%f se refere a uma variavel float\n",
    "    #informa ao usuario o valor definido para a rejeição\n",
    "    lista1.append(\"Dados são descritos ou não pela normal?\")\n",
    "    #Note que o comando append adiciona os elementos em sequencia, linha a linha\n",
    "    #nao se especifica indice, pois ja esta subentendido que esta na proxima\n",
    "    #linha\n",
    "    \n",
    "    #Lilliefors’ test\n",
    "    lilliefors_test = diagnostic.kstest_normal(y, dist='norm', pvalmethod='table')\n",
    "    #Return: linha 1: ksstat: float\n",
    "    #Kolmogorov-Smirnov test statistic with estimated mean and variance.\n",
    "    #Linha 2: p-value:float\n",
    "    #If the pvalue is lower than some threshold, e.g. 0.10, then we can reject the Null hypothesis that the sample comes from a normal distribution.\n",
    "    \n",
    "    #criar lista apenas com o p-valor\n",
    "    p_lillie = []\n",
    "    p_lillie.append(lilliefors_test[1]) #p-valor\n",
    "    p_lillie.append(100*lilliefors_test[1]) #p em porcentagem\n",
    "    p_lillie.append(alpha)\n",
    "    \n",
    "    if (lilliefors_test[1] < alpha):\n",
    "        p_lillie.append(\"p = %.3f < %.3f\" %(lilliefors_test[1], alpha))\n",
    "        p_lillie.append(\"Dados não são descritos pela normal\")\n",
    "    else:\n",
    "        p_lillie.append(\"p = %.3f >= %.3f\" %(lilliefors_test[1], alpha))\n",
    "        p_lillie.append(\"Dados são descritos pela normal\")\n",
    "        \n",
    "    \n",
    "    #Anderson-Darling\n",
    "    ad_test = diagnostic.normal_ad(y, axis=0)\n",
    "    #Return: Linha 1: ad2: float\n",
    "    #Anderson Darling test statistic.\n",
    "    #Linha 2: p-val: float\n",
    "    #The p-value for hypothesis that the data comes from a normal distribution with unknown mean and variance.\n",
    "    \n",
    "    #criar lista apenas com o p-valor\n",
    "    p_ad = []\n",
    "    p_ad.append(ad_test[1]) #p-valor\n",
    "    p_ad.append(100*ad_test[1]) #p em porcentagem\n",
    "    p_ad.append(alpha)\n",
    "    \n",
    "    if (ad_test[1] < alpha):\n",
    "        p_ad.append(\"p = %.3f < %.3f\" %(ad_test[1], alpha))\n",
    "        p_ad.append(\"Dados não são descritos pela normal\")\n",
    "    else:\n",
    "        p_ad.append(\"p = %.3f >= %.3f\" %(ad_test[1], alpha))\n",
    "        p_ad.append(\"Dados são descritos pela normal\")\n",
    "    \n",
    "    #NOTA: o comando %f apresenta a variavel float com todas as casas\n",
    "    #decimais possiveis. Se desejamos um numero certo de casas decimais\n",
    "    #acrescentamos esse numero a frente. Exemplos: %.1f: 1 casa decimal\n",
    "    # %.2f: 2 casas; %.3f: 3 casas decimais, %.4f: 4 casas\n",
    "    \n",
    "    d = {'Parâmetros e Interpretações': lista1, 'Teste de Lilliefors': p_lillie, 'Teste de Anderson-Darling': p_ad}\n",
    "    \n",
    "    #dicionario dos valores obtidos\n",
    "    df = pd.DataFrame(data = d)\n",
    "    #dataframe de saída\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "CELL_11"
    ]
   },
   "source": [
    "# CÉLULA 11: Função para avaliar normalidade dos dados\n",
    "\n",
    "### ATENÇÃO: NÃO EXECUTE ESTA CÉLULA - Ela contém apenas texto explicativo\n",
    "\n",
    "Avaliação se os dados seguem a distribuição normal, de acordo com os testes de Lilliefors e Anderson-Darling\n",
    "\n",
    "INSTRUÇÕES:\n",
    "\n",
    "1) Esta função retorna 1 dataframe:\n",
    "    dataframe df1 contendo os p-valores dos testes de normalidade dos dados.\n",
    "\n",
    "2) O parâmetro y da função deve ser apenas uma lista, não um dataframe.\n",
    "\n",
    "3) p-valor: probabilidade da hipótese-nula do teste de hipótese ser verdadeira\n",
    "\n",
    "Hipótese-nula H0: os dados seguem uma distribuição normal\n",
    "Hipótese alternativa H1: os dados não seguem a normal\n",
    "\n",
    "4) o p-valor é uma probabilidade, i.e., um valor entre 0 e 1\n",
    "\n",
    "5) 100 vezes o p-valor é a probabilidade em porcentagem\n",
    "        \n",
    "        Exemplo: se p = 0.20, a probabilidade é 0.20 ou 20% de os dados serem descritos pela normal\n",
    "\n",
    "6) Critério de rejeição: define-se um valor alpha tal que, se p < alpha, rejeitamos a hipótese-nula, ou seja, consideramos que os dados não seguem a normal\n",
    "\n",
    "###### 7) em geral, tomamos alpha = 0.10 - ou seja, se p < 0,10 (se há menos de 10% de probabilidade de seguirem a normal), consideramos que os dados não seguem a distribuição\n",
    "\n",
    "##### 8) Alguns autores são mais rigorosos, considerando alpha = 0.05 - ou seja, só rejeitam a normal se existe menos de 5% de probabilidade de os dados serem descritos por uma normal.\n",
    "\n",
    "### PORTANTO: MANTENHA alpha = 0.10 \n",
    "                \n",
    "                OU \n",
    "\n",
    "### ALTERE para alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_12"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 12: AVALIAÇÃO DE NORMALIDADE DOS SEUS DADOS\n",
    "\n",
    "#DEFINA A VARIAVEL y para a qual será construído o histograma. \n",
    "#Basta substituir o valor entre aspas pelo nome da coluna onde está Y:\n",
    "\n",
    "y = dataset['Y']\n",
    "\n",
    "#NOTA: o valor y necessariamente deve ser uma série.\n",
    "\n",
    "df = testes_normalidade(y = y, alpha = 0.10)\n",
    "\n",
    "\"\"\"\n",
    "Substitua o valor alpha de acordo com as instruções dadas na CÉLULA 11. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df\n",
    "\n",
    "\"\"\"VOCÊ DESEJA EXPORTAR OS DADOS?\n",
    "Caso deseje exportar os dados, copie a seguinte linha para o espaço não-vermelho após as aspas. Substitua o endereço pela\n",
    "pasta onde você deseja salvar seu arquivo. Substitua dataframe pelo nome que deseja para seu arquivo. Mantenha\n",
    "a extensão csv\n",
    "\n",
    "df.to_csv(r\"D:\\Drive\\FM2S\\EAD\\Green Belt em Python\\Machine Learning - módulo 3 - ANN classification\\ANN.Class - 1 - user satisfaction\\dataframe.csv\", index = False)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_13"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 13: Função para realizar a transformação Box-Cox dos dados (transformar os dados originais em dados que sejam \n",
    "representados por uma curva normal)\n",
    "\n",
    "#Execute esta CÉLULA para carregar a função\n",
    "\n",
    "def transf_box_cox(x, y, nome_x = None, limites_de_especificacao = None):\n",
    "    import pandas as pd\n",
    "    from statsmodels.stats import diagnostic\n",
    "    from scipy import stats\n",
    "    \n",
    "    lambda_boxcox = stats.boxcox_normmax(y, method='pearsonr')\n",
    "    #calcula o lambda da transformacao box-cox utilizando o metodo da maxima verossimilhanca\n",
    "    #por meio da maximizacao do coeficiente de correlacao de pearson da funcao\n",
    "    #y = boxcox(x), onde boxcox representa a transformacao\n",
    "    \n",
    "    #lista apenas com o lambda\n",
    "    lista_lambda = []\n",
    "    lista_lambda.append(lambda_boxcox)\n",
    "    #APENAS LISTAS PODEM ENTRAR CORRETAMENTE NO DICIONARIO\n",
    "    #Passo necessario para criacao dos novos dataframes\n",
    "    \n",
    "    #Calculo da variavel transformada\n",
    "    y_transform = stats.boxcox(y, lmbda=lambda_boxcox, alpha=None)\n",
    "    #Calculo da transformada\n",
    "    \n",
    "    if not (nome_x is None):\n",
    "        #apenas se existe o nome da variavel X\n",
    "        xlabel = nome_x\n",
    "    \n",
    "    else:\n",
    "        xlabel = \"X\"\n",
    "        \n",
    "    d1 = {xlabel: x, 'Dados transformados': y_transform}\n",
    "    #dicionario dos dados transformados\n",
    "    df1 = pd.DataFrame(data = d1)\n",
    "    #dataframe contendo os dados transformados\n",
    "    \n",
    "    #testes de normalidade da variavel transformada\n",
    "    #Lilliefors’ test\n",
    "    lilliefors_test = diagnostic.kstest_normal(y, dist='norm', pvalmethod='table')\n",
    "    #Return: linha 1: ksstat: float\n",
    "    #Kolmogorov-Smirnov test statistic with estimated mean and variance.\n",
    "    #Linha 2: p-value:float\n",
    "    #If the pvalue is lower than some threshold, e.g. 0.10, then we can reject the Null hypothesis that the sample comes from a normal distribution.\n",
    "    \n",
    "    #criar lista apenas com o p-valor\n",
    "    p_lillie = []\n",
    "    p_lillie.append(lilliefors_test[1])\n",
    "    #apenas o p-valor na lista\n",
    "    \n",
    "    #Anderson-Darling\n",
    "    ad_test = diagnostic.normal_ad(y, axis=0)\n",
    "    #Return: Linha 1: ad2: float\n",
    "    #Anderson Darling test statistic.\n",
    "    #Linha 2: p-val: float\n",
    "    #The p-value for hypothesis that the data comes from a normal distribution with unknown mean and variance.\n",
    "    \n",
    "    #criar lista apenas com o p-valor\n",
    "    p_ad = []\n",
    "    p_ad.append(ad_test[1])\n",
    "    #apenas o p-valor na lista\n",
    "    \n",
    "    d2 = {'Lambda da transformação Box-Cox': lista_lambda, 'p-valor teste Lilliefors': p_lillie, 'p-valor teste Anderson-Darling': p_ad}\n",
    "    #dicionario dos p-valores e do lambda\n",
    "    #Apenas possivel ao se criar as listas de valores individuais\n",
    "    df2 = pd.DataFrame(data = d2)\n",
    "    #dataframe dos p-valores e do lambda, cada um em uma coluna de nome apropriado\n",
    "    \n",
    "    if not (limites_de_especificacao is None):\n",
    "        #apenas executa este passo quando o limite de especificação for fornecido\n",
    "        \n",
    "        novos_limites = []\n",
    "        i = 0\n",
    "        while (i <2): \n",
    "            #a lista possui apenas os indices 0 e 1, correspondentes ao limite\n",
    "            #inferior e ao limite superior\n",
    "            if (limites_de_especificacao[i] == 0):\n",
    "                novos_limites.append(0)\n",
    "                #evitar o erro do exponencial igual a zero\n",
    "            else:\n",
    "                novos_limites.append(((limites_de_especificacao[i])**lambda_boxcox-1)/lambda_boxcox)\n",
    "                #aplica a transformada aos limites\n",
    "            \n",
    "            #a lista novos_limites grava os limites de especificação transformados\n",
    "            i = i + 1\n",
    "        \n",
    "        #aqui temos mais uma vez o problema da criação do dicionario\n",
    "        #poderiamos simplesmente retornar a lista, mas não seria possível separar\n",
    "        #colunas com nomes. Para isso, fazemos:\n",
    "            \n",
    "        lista_inf = []\n",
    "        lista_inf.append(novos_limites[0])\n",
    "        #apenas o limite inferior\n",
    "        \n",
    "        lista_sup = []\n",
    "        lista_sup.append(novos_limites[1])\n",
    "        # assim, garantimos que se um dos limites for zero, nao havera erro\n",
    "        #na funcao exponencial, pois checamos tanto o inferior quanto o superior\n",
    "        # e podemos criar um dataframe com as colunas indicadas por nomes\n",
    "        \n",
    "        d3 = {'Limite de especificação inferior transformado': lista_inf,\n",
    "              'Limite de especificação superior transformado': lista_sup}\n",
    "        \n",
    "        df3 = pd.DataFrame(data = d3)\n",
    "        #dataframe dos novos limites de especificação\n",
    "    \n",
    "    if not (limites_de_especificacao is None):\n",
    "        #Caso haja limites de especificacao, retorna os limites transformados\n",
    "        return df1, df2, df3\n",
    "    \n",
    "    #caso nao haja limite de especificacao:\n",
    "    else:\n",
    "        return df1, df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "CELL_14"
    ]
   },
   "source": [
    "# CÉLULA 14: Função para transformação Box-Cox\n",
    "\n",
    "### ATENÇÃO: NÃO EXECUTE ESTA CÉLULA - Ela contém apenas texto explicativo\n",
    "    \n",
    "    \n",
    "Utilize este sistema para transformar dados que não seguem a normal em dados que são representados por uma distribuição normal.\n",
    "\n",
    "INSTRUÇÕES:\n",
    "\n",
    "1) Esta função retorna 2 ou 3 dataframes:\n",
    "\n",
    "        1 dataframe df1 contendo os dados transformados (SEMPRE)\n",
    "        1 dataframe df2 contendo os p-valores dos testes de normalidade dos dados transformados (SEMPRE)\n",
    "        1 dataframe df3 contendo os limites de especificação transformados (apenas quando forem fornecidos limites de especificação).\n",
    "\n",
    "2) Caso não sejam fornecidos limites de especificação, chame dois dataframes\n",
    "\n",
    "Exemplo: caso deseje salvar o dataframe df1 em y1, o dataframe df2 em y2 e os dados a serem transformados estão na variável y:\n",
    "    \n",
    "        y1, y2 = transf_box_cox(x, y, nome_x = None, limites_de_especificacao = None)\n",
    "    \n",
    "Você pode dar outros nomes para os dataframes chamados:\n",
    "    \n",
    "        dados_transformados, p_vals = transf_box_cox(x, y, nome_x = None, limites_de_especificacao = None)\n",
    "        \n",
    "3) Os parâmetros x e y da função devem ser apenas listas, não dataframes.\n",
    "        \n",
    "        Forneça os valores originais do eixo X\n",
    "    \n",
    "4) Caso haja limites de especificação, declare-os como uma lista de 2 valores\n",
    "\n",
    "Exemplos: se a especificação é de 10 a 20 kg\n",
    "    \n",
    "        limites_de_especificacao = [10, 20]\n",
    "\n",
    "- se a especificação está entre 0 a 12.5 L:\n",
    "\n",
    "        limites_de_especificacao = [0, 12.5]\n",
    "\n",
    "-Se não houver limites de especificação, manter:\n",
    "    \n",
    "        limites_de_especificacao = None\n",
    "\n",
    "-A função retornará os limites já transformados\n",
    "\n",
    "5) CASO SEJAM FORNECIDOS LIMITES DE ESPECIFICAÇÃO, você precisará chamar 3 dataframes:\n",
    "\n",
    "        y1, y2, y3 = transf_box_cox(x, y, nome_x = None, limites_de_especificacao = [lim_inf, lim_sup])\n",
    "\n",
    "Assim, supondo que os limites sejam 10 e 20 kg, e a variável seja y\n",
    "\n",
    "        y1, y2, y3 = transf_box_cox(x, y, nome_x = None, limites_de_especificacao = [10, 20])\n",
    "\n",
    "ou com os nomes desejados, por exemplo:\n",
    "    \n",
    "        dados_transformados, p_vals, lim_transformados = transf_box_cox(x, y, nome_x = None, limites_de_especificacao = [10, 20])\n",
    "\n",
    "6) Caso não queira fornecer o nome da variável X, mantenha nome_x = None\n",
    "    Caso queira, coloque o nome entre aspas. \n",
    "    Por exemplo: nome_x = \"Dias da semana\" ou\n",
    "    nome_x = \"Coleta\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "CELL_15"
    ]
   },
   "outputs": [],
   "source": [
    "## CÉLULA 15: TRANSFORMAÇÃO BOX-COX DOS SEUS DADOS\n",
    "\n",
    "#DEFINA A VARIAVEL X. Basta substituir o valor entre aspas pelo nome da coluna onde está X:\n",
    "x = dataset['X']\n",
    "\n",
    "#DEFINA A VARIAVEL y. Basta substituir o valor entre aspas pelo nome da coluna onde está Y:\n",
    "y = dataset['Y']\n",
    "\n",
    "\"\"\"\n",
    "Se os seus dados possuírem limites de especificação a serem definidos, substitua a linha do comando imediatamente após\n",
    "as aspas pela seguinte linha. Isso porque a linha do comando resulta em 2 dataframes, mas será necessária uma terceira\n",
    "saída para os novos limites de especificação.\n",
    "\n",
    "\n",
    "dados_transformados, p_vals, lim_transformados = transf_box_cox(x, y, nome_x = None, limites_de_especificacao = [lim_inf, lim_sup])\n",
    "\n",
    "\n",
    "\n",
    "- Não se esqueça de substituir lim_inf pelo valor do limite inferior de especificação, e lim_sup pelo do limite superior.\n",
    "Esta substituição não é necessária se as variáveis lim_inf e lim_sup forem definidas e tiverem seus valores especificados antes\n",
    "de chamar a função.\n",
    "Lembre-se que os limites_de_especificacao devem ser fornecidos no formato [2.71, 3.50] \n",
    "(dois valores sequenciais, separados por vírgula, e entre colchetes. O primeiro é o limite de especificação inferior, \n",
    "e o segundo é o superior).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "dados_transformados, p_vals = transf_box_cox(x = x, y = y, nome_x = None, limites_de_especificacao = None)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Substitua os demais campos None de acordo com as instruções dadas na CÉLULA 14. \n",
    "- O nome da variável X deve ser FORNECIDO ENTRE ASPAS. Por exemplo: nome_x = \"x\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "dados_transformados\n",
    "p_vals\n",
    "\n",
    "#acrescente mais uma linha contendo apenas lim_transformados caso estes valores tenham sido calculados. Basta remover o #\n",
    "#da próxima linha (ela deixará de ser um comentário e se tornará um comando):\n",
    "\n",
    "#lim_transformados\n",
    "\n",
    "\"\"\"VOCÊ DESEJA EXPORTAR OS DADOS?\n",
    "Caso deseje exportar os dados, copie as seguintes linhas para o espaço não-vermelho após as aspas. Substitua o endereço pela\n",
    "pasta onde você deseja salvar seu arquivo. Substitua data_transform, p_valores, e lim_transform pelos nomes que deseja para seus arquivos. \n",
    "Mantenha a extensão csv. Você pode também optar por exportar apenas uma das tabelas (neste caso, copie apenas a desejada).\n",
    "\n",
    "dados_transformados.to_csv(r\"D:\\Drive\\FM2S\\EAD\\Green Belt em Python\\Machine Learning - módulo 3 - ANN classification\\ANN.Class - 1 - user satisfaction\\data_transform.csv\", index = False)\n",
    "\n",
    "p_vals.to_csv(r\"D:\\Drive\\FM2S\\EAD\\Green Belt em Python\\Machine Learning - módulo 3 - ANN classification\\ANN.Class - 1 - user satisfaction\\p_valores.csv\", index = False)\n",
    "\n",
    "lim_transformados.to_csv(r\"D:\\Drive\\FM2S\\EAD\\Green Belt em Python\\Machine Learning - módulo 3 - ANN classification\\ANN.Class - 1 - user satisfaction\\lim_transform.csv\", index = False)\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
